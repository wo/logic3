\chapter{Arithmetical Representability}\label{ch:representability}

\section{A look ahead}

We're going to prove Gödel's incompleteness theorem.
We'll show that
every consistent theory of arithmetic (in the language $\L_{A}$)
with a computable set of axioms
is \emph{incomplete} in the sense that
there are arithmetical sentences $A$ which
the theory can neither prove nor refute.

We focus on arithmetic for two reasons.
One, it's a comparatively simple and familiar branch of maths.
If arithmetic can't be adequately axiomatized,
then evidently the same is true for more powerful theories.
Two, the proof of Gödel's theorem requires that
the theory in question has the resources to
express basic facts about what can and can't be proved.
Arithmetic theories satisfy this requirement.

(In a sense, arithmetic is the computational fragment of maths: computations on
any domain can be encoded as arithmetic computations.
Once we've shown that every total recursive function is expressible in $L_{A}$, what
remains to be shown is that if we code the elements of other domains as numbers,
computable operations on these domains will be recursive operations on numbers.)

Of course,
some theories of arithmetic are complete.
The restriction to a computable set of axioms is important.

\begin{definition}{Recursive Axiomatizability}{recursive-axiomatizability}
  A theory is \emph{recursively axiomatizable} if it contains all and only the
  sentences derivable from some recursive set of axioms.
\end{definition}

Remember that proofs from computable axioms are ``verifiable''.
There is an algorithm for checking that something is a proof.
We've already seen that
algorithms can generally be represented as operating on numbers,
with a suitable coding and decoding of the inputs and outputs.
We can code each $\L_{A}$-sentence and each sequence of $\L_{A}$-sentences by a number,
called the gn.
Since there is an algorithm
for checking whether a sequence is a proof of some target sentence,
it follows by Church's Thesis that
the relation Prf(x,y) is recursive.

Prf is a relation between numbers.
As such,
we may wonder if it can be expressed in $\L_{A}$,
in terms of $+$, $\times$, $s$, and $0$.
The answer is yes.
So there is an $\L_{A}$-formula $Prf(x,y)$ so that
$Prf(n,m)$ is true (in the standard model of arithmetic) iff
$n$ codes a proof of the sentence coded by $m$.
From this,
we can construct a formula $Prov(y)$ as $\exists x Prf(x,y)$ so that
$Prov(y)$ is true iff
$y$ is provable.
Again,
this will be a purely arithmetical formula,
couched in terms of $+$, $\times$, $s$, and $0$.

Using an ingenious trick due to Gödel,
we'll then show that
for every $\L_{A}$-formula
there is an $\L_{A}$-sentence that is true iff
the formula is true of the gödel number of that very sentence.
Thus,
in particular,
there is a sentence $G$ that is true iff
$\neg Prov(x)$ is true of $G$.
That is,
we'll find an arithmetical sentence $G$ that is true iff it is not provable.

Now suppose $G$ is provable,
in some computably axiomatized theory $T$.
Then $G$ is false,
as it is true iff it is not provable.
So if an arithmetical theory $T$ doesn't prove false sentences,
then it can't prove $G$.
In this case,
$G$ is true.
So $T$ can't prove its negation either,
as the negation is false.
So any sound (computably axiomatized) $\L_{A}$-theory is incomplete.

This result is sometimes called the \emph{semantic incompleteness theorem}.
It is ``semantic'' because it involves the concept of arithmetical truth,
which is a semantic concept.
Gödel himself focussed on a different version of the incompleteness theorem
that only relies on syntactic concepts of arithmetical theories.
He showed that
any axiomatic $\L_{A}$-theory of reasonable strength can prove
all true statements of the form $Prf(n,m)$ and $\neg Prf(n,m)$.
xxxx

What we need to show, then, is that
the Prf relation can be expressed in $\L_{A}$
and, moreover, that reasonably strong arithmetical theories can
prove all true statements of the form $Prf(n,m)$ and $\neg Prf(n,m)$.

In this chapter, we are going to show something much more general:
every recursive relation $R$ is expressible in $\L_{A}$.
and reasonably strong arithmetical theories can prove all true statements of the form $R(n,m)$ and $\neg R(n,m)$.
This more general fact will help get a deeper understanding of
the nature and limitations of axiomatized theories.

\begin{exercise}
  Show that if a theory is r. ax. and complete then it is decidable. (appeal
  lazily to Church's Theorem)
\end{exercise}


\section{Definability and representability}

There are many recursive relations on numbers.
Everything that's computable is recursive, by Church's Thesis.
For example,
all of the following express recursive relations,
as there is a mechanical procedure for deciding whether the relation holds of given numbers $x,y,z$:

\begin{itemize}
  \item $z$ is the sum of $x$ and $y$.
  \item $x$ is less than $y$.
  \item $z$ is a common divisor of $x$ and $y$.
  \item $x$ is a prime factor of $y$.
  \item $x$ is a root of the polynomial coded by $y$.
  \item $x$ is the code number of a Turing machine.
  \item $x$ is the code number of a Turing machine that halts on input $y$ within $z$ steps.
\end{itemize}

The first of these is obviously expressible in $\L_{A}$,
by the formula $x+y=z$.
It's not obvious,
however,
that any of the others are expressible,
given that the only non-logical symbols in $\L_{A}$ are `0', `s', `+', and `$\times$'.
Indeed,
one can show that
multiplication cannot be expressed in terms of `0', `s', and `+':
One might expect that
exponentiation likewise can't be expressed in terms of `0', `s', `+', and `$\times$',
and that, in general,
infinitely many non-logical symbols are needed to express all recursive relations.
But not so.

Let's begin with the less-than relation.
I claim that
any statement of the form $t_{1} < t_{2}$,
where $t_{1}$ and $t_{2}$ are $\L_{A}$-terms,
can be translated into an $\L_{A}$-formula.
Can you see how?

There are many correct answers.
A simple one is this:
\[
  \exists z(t_{1} + s(z) = t_{2}).
\]
This works because
a (natural) number $a$ is less than a number $b$ iff
there is a number $c$ such that $a + (c+1) = b$.
We say that the formula
\[
  \exists z(x + s(z) = y)
\]
\emph{defines} or \emph{expresses} the less-than relation $<$ in $\L_{A}$.
It does so because it is true of numbers $a$ and $b$ iff $a < b$.
(Remember the concept `true of' from section xxx.)

In some ways,
the definition of $<$ resembles our definition
(way back in chapter 1)
of conjunction and disjunction
in terms of `$\neg$' and `$\land$'.
We don't need a symbol `$\land$' for conjunction in $\L_{A}$
because `$A \land B$' can be defined as an abbreviation of `$\neg(A \to \neg B)$'.
Likewise,
we don't need a symbol `$<$' because
`$t_{1} < t_{2}$' can be defined as an abbreviation of `$\exists z(t_{1} + s(z) = t_{2})$'.
But there is an important difference.
If we had a primitive symbol `$<$' for the less-than relation,
`$t_{1} < t_{2}$' would not be \emph{logically equivalent} to `$\exists z(t_{1} + s(z) = t_{2})$'.
That's because we don't count arithmetical symbols like `$+$' and `<' as logical symbols.
When we look for expressions for recursive relations,
we don't abstract away from the meaning of the non-logical symbols in $\L_{A}$.
We look for formulas that express the relations
\emph{on the intended interpretation of $\L_{A}$.}

\begin{exercise}
  Describe an interpretation of '$<$', `+', `$s$', and `0' that makes $0 < s(0)$ true but
  $\exists z(0 + s(z) = s(0))$ false.
\end{exercise}

To formulate the concept of expression more precisely,
let's use `$\num{n}$' to stand for the $\L_{A}$-numeral that names the number $n$.
Thus $\num{0}$ is `0',
$\num{1}$ is `$s(0)$', $\num{2}$ is `$s(s(0))$', and so on.

\begin{definition}{}{express}
    An $\L_{A}$-formula $A(x_{1},\ldots,x_{n})$ \emph{expresses} (or \emph{defines}) an
    $n$-place relation $R$ on $\mathbb{N}$ in $\L_{A}$ iff,
    for all numbers $a_{1},\ldots,a_{n}$,
    $A(\num{a_{1}},\ldots,\num{a_{n}})$ is true in the standard model of arithmetic iff
    $a_{1},\ldots,a_{n}$ stand in the relation $R$.

    Similarly,
    an $\L_{A}$-formula $A(x_{1},\ldots,x_{n},y)$ \emph{expresses} (or \emph{defines}) a total $n$-ary function $f$ on $\mathbb{N}$ in $\L_{A}$ iff,
    for all numbers $a_{1},\ldots,a_{n},b$,
    $A(\num{a_{1}},\ldots,\num{a_{n}},\num{b})$ is true in the standard model iff
    $f(a_{1},\ldots,a_{n}) = b$.
\end{definition}

We say that a relation or function is \emph{expressible} in $\L_{A}$ if it is expressed by some formula in $\L_{A}$.

Note that
according to definition \ref{def:express},
arithmetical functions are represented not by functional $\L_{A}$-terms,
but by formulas.
For example,
the addition function is represented by $x+y=z$,
not by $x+y$.
That's because there often won't be a suitable term,
and a formula is enough to do its job.
For example,
there is no $\L_{A}$-term $f(x)$ that
expresses the factorial function,
in the sense that
\[
  f(\num{a}) = a! = 1 \times 2 \times \ldots \times a,
\]
for all natural numbers $a$.
But we'll see that there is a formula $F(x,y)$ such that
$F(\num{a},\num{b})$ is true iff $b = a!$.
We can then express,
for example,
the relation $x < x!$
by, say,
\[
  \forall y(F(x,y) \to x < y).
\]

It's not entirely clear
how a non-total function could be expressed in $\L_{A}$.
Definition \ref{def:express} only covers total functions,
and that will be enough for our purposes.

\begin{exercise}
  Find an $\L_{A}$-formula that expresses the switcheroo function,
  which maps any positive number to 0 and 0 to 1.
\end{exercise}

In the next section,
we'll show that all total recursive functions are expressible in $\L_{A}$.
It will follow that
all recursive relations are expressible in $\L_{A}$,
because a relation is recursive iff its characteristic function is recursive
(and characteristic functions are always total).

We'll use the obvious induction strategy.
First,
we'll first show that
the base functions zero, successor, and identity are expressible in $\L_{A}$.
Then,
we'll show that
if some functions are expressible in $\L_{A}$
then so are any functions definable from them by composition, primitive recursion, and regular minimization.

In fact,
we'll show something stronger.
To explain what that is,
return to the fact that
`$+$', ``$\times$', `$s$' and `0' are non-logical symbols.
They have an ``intended interpretation'',
but this interpretation isn't built into the language.
This matters when we think of the axiomatic approach to arithmetic.
An axiomatic $\L_{A}$-theory is just a set of $\L_{A}$-sentences.
The theory doesn't ``know'' what the non-logical symbols mean.
Just because it is \emph{true}, on the intended interpretation, that 1+2=3
doesn't mean that an axiomatic theory can prove the sentence $\num{1} + \num{2} = \num{3}$.
The theory axiomatized by the empty set of axioms, for example, can't prove this.
That's why
an axiomatic theory of arithmetic needs non-logical axioms.

Peano Arithmetic has suitable axioms.
It can easily prove $\num{1} + \num{2} = \num{3}$.
In general,
for any numbers $a,b,c$
if $a+b=c$ then
Peano Arithmetic can prove `$\num{a} + \num{b} = \num{c}$',
In that sense,
Peano Arithmetic ``knows'' all particular facts about addition.
We say that the formula $x+y=z$ \textit{represents} the addition function in Peano Arithmetic.

Similarly,
the formula $\exists z(x + s(z) = y)$ not only expresses the less-than relation in $\L_{A}$,
it also represents that relation in Peano Arithmetic,
insofar as Peano Arithmetic can
prove all true instances of the formula
and refute all false ones:
whenever $a < b$, Peano Arithmetic can prove $\exists z(\num{a} + s(z) = \num{b})$,
and whenever $a \not< b$, Peano Arithmetic can prove $\neg\exists z(\num{a} + s(z) = \num{b})$.

\begin{definition}{}{represents}
  An $\L_{A}$-formula $A(x_{1},\ldots,x_{n})$ \emph{(numeralwise) represents} an $n$-ary relation $R$ on $\mathbb{N}$ in a theory $T$ iff, for all numbers $a_{1},\ldots,a_{n}$,
  \begin{enumerate}[(i)]
    \item if $R$ holds of $a_{1},\ldots,a_{n}$, then $\proves_{T} A(\num{a_{1}},\ldots,\num{a_{n}})$, and
    \item if $R$ does not hold of $a_{1},\ldots,a_{n}$, then $\proves_{T} \neg A(\num{a_{1}},\ldots,\num{a_{n}})$.
  \end{enumerate}

  An $\L_{A}$-formula $A(x_{1},\ldots,x_{n},y)$ \emph{(numeralwise) represents} a total $n$-ary function $f$ on $\mathbb{N}$ in a $T$ iff, for all numbers $a_{1},\ldots,a_{n},b$,
  \begin{enumerate}[(i)]
    \item if $f(a_{1},\ldots,a_{n}) = b$, then $\proves_{T} A(\num{a_{1}},\ldots,\num{a_{n}},\num{b})$, and
    \item $\proves_{T} \forall y(A(\num{a_{1}},\ldots,\num{a_{n}},y) \to y = \num{b})$.
  \end{enumerate}
\end{definition}

If a relation or function is represented in a theory $T$ by some formula,
we say that it is \emph{representable} in $T$.

You may wonder about the second condition for functions in definition \ref{def:represents}.
This is needed for cases where (unlike in the case of addition)
the relevant function isn't expressed by a functional term of $\L_{A}$.
Remember that we'll find an $\L_{A}$-formula $F(x,y)$
that is true of numbers $a$ and $b$ iff $b = a!$.
Condition (i) in the second part of definition \ref{def:represents} requires that
whenever $b = a!$,
then $F(\num{a},\num{b})$ is provable in $T$.
This leaves open that
$T$ also proves $F(\num{a},\num{c})$ for some $c \not= b$.
Indeed,
the formula $x\!=\!x \land y\!=\!y$ passes condition (i)
in any theory $T$.
But there's no good sense in which this formula represents the factorial function.
That's why we demand that
the theory must be able to prove not only $F(\num{a},\num{b})$,
but also that there is no other number $c$ such that $F(\num{a},\num{c})$.

\begin{exercise}
  Suppose we swap `+' and `$\times$' everywhere in the Peano axioms.
  Does $x+y$ still represent addition in the resulting theory?
  Can you give an expression that does?
\end{exercise}

Now I can explain what we're going to show.
We'll show that
all total recursive functions are representable in any
arithmetical theory of a certain minimal strength.
The formulas that represent the relevant functions in these theories
will also express them in $\L_{A}$.
So we'll prove the claim about expressibility via the claim about representability.

As in the case of expressibility,
we can focus on (total) functions
because the representability of all recursive (total) functions
entails the representability of all recursive relations,
in any theory that can prove that $0 \not= 1$.

\begin{proposition}
  A relation $R$ is strongly representable in a theory $T$ whenever
  its characteristic function $f_{R}$ is representable in $T$,
  provided that $\proves_{T} 0 \not= \num{1}$.
\end{proposition}
\begin{proof}
  Assume $A(x_{1},\ldots,x_{n},y)$ represents the characteristic function $f_{R}$ of $R$ in $T$.
  This means that whenever $R$ holds of $a_{1},\ldots,a_{n}$,
  then $\proves_{T} A(\num{a_{1}},\ldots,\num{a_{n}},\num{1})$,
  by condition (i) for representability of functions.
  Moreover,
  whenever $R$ does not hold of $a_{1},\ldots,a_{n}$,
  then $\proves_{T} A(\num{a_{1}},\ldots,\num{a_{n}},0)$ by condition (i)
  and $\proves_{T} \forall yA(\num{a_{1}},\ldots,\num{a_{n}},y) \to y=0$ by condition (ii).
  Assuming that $\proves_{T} 0 \not= \num{1}$,
  it follows that $A(x_{1},\ldots,x_{n},1)$ represents $R$ in $T$.
\end{proof}

\begin{exercise}
  Show that the converse is also true:
  if a relation is representable in a theory,
  then its characteristic function is representable in that theory.
\end{exercise}

  % Conversely,
  % assume that $A(x_{1},\ldots,x_{n})$ represents $R$ in $T$.
  % Let $B(x_{1},\ldots,x_{n},y)$ be the formula
  % \[
  %   (A(x_{1},\ldots,x_{n}) \land y\!=\!\num{1}) \lor
  %   (\neg A(x_{1},\ldots,x_{n}) \land y\!=\!0).
  % \]
  % I claim that $B(x_{1},\ldots,x_{n},y)$ represents the characteristic function $f_{R}$ of $R$ in $T$.
  % We have to verify the two conditions for representation.

  % We take the two possible values of $f_{R}(a_{1},\ldots,a_{n})$ in turn.
  % Assume first that $f_{R}(a_{1},\ldots,a_{n}) = 1$.
  % Then $R$ holds of $a_{1},\ldots,a_{n}$,
  % and by assumption $\proves_{T} A(\num{a_{1}},\ldots,\num{a_{n}})$.
  % In that case, we also have $\proves_{T} A(\num{a_{1}},\ldots,\num{a_{n}}) \land \num{1} = \num{1}$ and thereby $\proves_{T} B(\num{a_{1}},\ldots,\num{a_{n}},\num{1})$.
  % So the first condition for representability is satisfied.
  % The second condition requires that
  % $\proves_{T} \forall y(B(\num{a_{1}},\ldots,\num{a_{n}},y) \to y = \num{1})$.
  % This follows by construction of $B$.

  % By completely parallel reasoning,
  % we can show that
  % if $f_{R}(a_{1},\ldots,a_{n}) = 0$,
  % then $\proves_{T} B(\num{a_{1}},\ldots,\num{a_{n}},0)$ and
  % $\proves_{T} \forall y(B(\num{a_{1}},\ldots,\num{a_{n}},y) \to y = 0)$.

\section{Conditions for Representability I}

All total recursive functions can be constructed from
the base functions $z$ (zero), $s$ (successor), and $id^{n}_{i}$ (identity) by
iterated application of
composition, primitive recursion, and regular minimization.
In what follows,
we'll study what a theory has to ``know''
so that the base functions are representable in it.
Then we'll study what it has to know
so that representability is closed under the three operations.
We'll find that the theory must satisfy six conditions.
Thus,
all recursive functions are representable in any theory that satisfies these six conditions.

let's start with the zero function.
Remember what is required,
in general,
for a formula $A(x,y)$ to represent a one-place function $f$ in a theory $T$.
Two conditions must be satisfied, for all numbers $a$:

\begin{enumerate}[(i)]
  \item $\vdash_{T} A(\num{a}, \num{f(a)})$.
  \item $\vdash_{T} \forall y(A(\num{a},y) \to y = \num{f(a)})$.
\end{enumerate}

(Here, $\num{f(a)}$ is the $\L_{A}$-numeral for the number that $f$ returns for $a$.
It consists of $f(a)$ occurrences of `$s($',
followed by `0', followed by $f(a)$ occurrences of `)'.)
Let's apply this to the zero function,
which maps every number $a$ to $0$.
In this case,
$\num{f(a)}$ is always `0'.
So we're looking for a formula $A(x,y)$ such that

\begin{enumerate}[(i)]
  \item $\vdash_{T} A(\num{a}, 0)$;
  \item $\vdash_{T} \forall y(A(\num{a},y) \to y = 0)$.
\end{enumerate}

Such a formula is not hard to find.

\begin{lemma}{}{zero-repr}
   The zero function $z$ is represented in every theory by the formula $x=x \land y=0$.
\end{lemma}

\begin{proof}
  With $x=x \land y=0$ in place of $A(x,y)$,
  the first representability condition requires that $T$ can prove
  \[
    \num{a}=\num{a} \land 0=0.
  \]
  The second condition requires that $T$ can prove
  \[
    \forall y((\num{a}=\num{a} \land y=0) \to y=0).
  \]
  Both of these are logical truths (for all $a$).
  Any theory whatever can prove them.
\end{proof}

The situation for the successor and identity functions is parallel.
These,
too, are representable in any theory whatsoever.

\begin{lemma}{}{succ-repr}
  The successor function is represented in every theory by the formula $s(x)=y$.
\end{lemma}

\begin{proof}
  Exercise.
\end{proof}

% \begin{proof}
%   We need to show:
%   \begin{enumerate}[(i)]
%     \item For all $a$, $\vdash_{T} s(\num{a}) = \num{a+1}$.
%     \item For all numbers $a$, $\vdash_{T} \forall y(s(\num{a})=y \to y = \num{a+1})$.
%   \end{enumerate}
%   (ii) follows from (i) by standard predicate logic.
%   (i) is a logical truth because the $\L_{A}$-numeral $\num{a+1}$ is $s(\num{a})$.
% \end{proof}

\begin{lemma}{}{proj-repr}
  Each identity function $id^{n}_{i}$ is represented in every theory by
  the formula $x_{1}=x_{1} \land \ldots \land x_{n}=x_{n} \land y=x_{i}$.
\end{lemma}

\begin{proof}
  Exercise.
\end{proof}

\begin{exercise}
  Proof the previous two lemmas.
\end{exercise}

% \begin{proof}
%   We need to show:
%   \begin{enumerate}[(i)]
%     \item For all $a_{1},\ldots,a_{n}$, $\vdash_{T} \num{a_{1}}=\num{a_{1}} \land \ldots \land \num{a_{n}}=\num{a_{n}} \land \num{a_{i}}=\num{a_{i}}$.
%     \item For all numbers $a_{1},\ldots,a_{n}$, $\vdash_{T} \forall y(\num{a_{1}}=\num{a_{1}} \land \ldots \land \num{a_{n}}=\num{a_{n}} \land y=\num{a_{i}} \to y = \num{a_{i}})$.
%   \end{enumerate}
% \end{proof}

At this point,
we've figured out that the base functions are representable in any theory whatsoever.
The theory doesn't yet need to know anything.
Now for the closure operations.
We start with composition.

Assume that
$h$ is the composition of two (one-place) functions $f$ and $g$,
so that $h(x) =f(g(x))$.
Assume also that $f$ and $g$ are represented in $T$ by formulas $F(x,y)$ and $G(x,y)$,
respectively.
We want to find a formula that represents $h$.
Note that $h(x) = y$ iff there is a $v$ such that $g(x) = v$ and $f(v) = y$.
So the following formula is a natural candidate to represent $h$:
\[
  \exists v(G(x,v) \land F(v,y)).
\]
It remains to check that this formula satisfies the two conditions for representability.
It turns out that this follows
from the representability conditions for $F$ and $G$.

\begin{lemma}{}{repr-cn}
  If an $m$-place function $f$ is represented in a theory $T$ by a formula $F(x_{1},\ldots,x_{m},y)$,
  and $m$ $n$-place functions $g_{1},\ldots,g_{m}$ are represented in $T$ by formulas
  and $G_{1}(x_{1},\ldots,x_{n},y_{1}),\ldots,G_{m}(x_{1},\ldots,x_{n},y_{m})$,
  respectively,
  then the composition $h = Cn[f,g_{1},\ldots,g_{m}]$ is represented in $T$ by the formula
  \[
    \exists v_{1}\ldots \exists v_{m}\,(G_{1}(x_{1},\ldots,x_{n},v_{1}) \land \ldots \land
    G_{m}(x_{1},\ldots,x_{n},v_{m}) \land F(v_{1},\ldots,v_{m},y)).
  \]
\end{lemma}
\begin{proof}
  I'll give the proof for the case where $n=1$ and $m=2$.
  The proof for arbitrary $n$ and $m$ is completely analogous and not much harder to write;
  but it's harder to read.

  The first condition on representability requires that whenever $h(a) = b$,
  then
  \[
    \proves_{T} \exists v_{1}\exists v_{2}(G_{1}(\num{a},v_{1}) \land G_{2}(\num{a},v_{2}) \land F(v_{1},v_{2},\num{b})).
  \]
  So assume $h(a) = b$.
  Then there are $c_{1},c_{2}$ such that
  $g_{1}(a) = c_{1}$, $g_{2}(a) = c_{2}$, and $f(c_{1},c_{2}) = b$.
  Since $g_{1}$ and $g_{2}$ are represented by $G_{1}(x,y_{1})$ and $G_{2}(x,y_{2})$,
  respectively,
  and $f$ is represented by $F(x_{1},x_{2},y)$,
  we have
  \begin{gather*}
    \proves_{T} G_{1}(\num{a},\num{c_{1}}) \\
    \proves_{T} G_{2}(\num{a},\num{c_{2}}) \\
    \proves_{T} F(\num{c_{1}},\num{c_{2}},\num{b}).
  \end{gather*}
  The desired claim follows by closure under first-order consequence.

  For the second condition,
  we have to show that
  \[
    \proves_{T} \forall y(\exists v_{1}\exists v_{2}(G_{1}(\num{a},v_{1}) \land G_{2}(\num{a},v_{2}) \land F(v_{1},v_{2},y)) \to y = \num{b}).
  \]
  This, too, follows from the representability conditions for $F$, $G_{1}$, and $G_{2}$,
  which yield
  \begin{gather*}
    \proves_{T} \forall y(G_{1}(\num{x},y) \to y = \num{c_{1}}) \\
    \proves_{T} \forall y(G_{2}(\num{x},y) \to y = \num{c_{2}}) \\
    \proves_{T} \forall y(F(c_{1},c_{2},y) \to y = \num{b}).
  \end{gather*}
\end{proof}

% \begin{proof}
%   For the first condition,
%   assume $h(a_{1},\ldots,a_{n}) = b$.
%   Then there are some $c_{1},\ldots,c_{m}$ such that
%   for all $g_{i}$,
%   $g_{i}(a_{1},\ldots,a_{n}) = c_{i}$ and $f(c_{1},\ldots,c_{m}) = b$.
%   Since each $g_{i}$ is represented by $G_{i}(x_{1},\ldots,x_{n},y_{i})$,
%   and $f$ by $F(x_{1},\ldots,x_{m},y)$,
%   we have
%   \begin{gather*}
%     \vdash_{Q} G_{1}(\num{a_{1}},\ldots,\num{a_{n}},\num{c_{1}}) \\
%     \vdash_{Q} \ldots \\
%     \vdash_{Q} G_{m}(\num{a_{1}},\ldots,\num{a_{n}},\num{c_{m}}) \\
%     \vdash_{Q} F(\num{c_{1}},\ldots,\num{c_{m}},\num{b}).
%   \end{gather*}
%   It follows (by closure under first-order consequences) that
%   \[
%     \vdash_{Q} \exists v_{1}\ldots \exists v_{m}\,(G_{1}(\num{a_{1}},\ldots,\num{a_{n}},v_{1}) \land \ldots \land
%     G_{m}(\num{a_{1}},\ldots,\num{a_{n}},v_{m}) \land F(v_{1},\ldots,v_{m},\num{b})).
%   \]
%   The first condition for representability is thereby satisfied.

%   The second is also satisfied,
%   for the assumption that $G_{1},\ldots,G_{m},F$ represent $g_{1},\ldots,g_{m},f$
%   means that
%   \begin{gather*}
%     \vdash_{Q} \forall y(G_{1}(\num{x},y) \to y = \num{c_{1}}) \\
%     \ldots\\
%     \vdash_{Q} \forall y(G_{m}(\num{x},y) \to y = \num{c_{m}}) \\
%     \vdash_{Q} \forall y(F(c_{1},\ldots,c_{m},y) \to y = \num{b}).
%   \end{gather*}
%   And this entails
%     \[
%         \vdash_{Q} \forall y(\exists v_{1}\ldots \exists v_{m}\,(G_{1}(\num{a},v_{1}) \land \ldots \land
%         G_{m}(\num{a},v_{m}) \land F(v_{1},\ldots,v_{m},y)) \to y = \num{b}).
%     \]
% \end{proof}

I leave the case of primitive recursion for last:
it is by far the hardest.
Let's look at regular minimization.

Suppose $h = Mn[f]$, where $f$ is a regular function.
This means that
for any input number $x$,
$h$ returns the smallest number $y$ for which $f(x,y)$ is 0.
Assuming that $f$ is represented in $T$ by some formula $F(x,y)$,
we have $h(x) = y$ iff $F(x,y,0)$ and there is no $z < y$ such that $F(x,z,0)$.
We can directly translate this into $\L_{A}$:
\[
  F(x,y,0) \land \forall z(z < y \to \neg F(x,z,0)).
\]
Some assumptions are needed for this formula to represent $h$ in a theory $T$.
Informally speaking,
the theory must have some idea of what $<$ means.
Specifically,
$T$ must satisfy the following conditions:

\begin{axioms}
  R1 & $\text{For all }a\text{, }\vdash_{T} \forall x (\num{a} < x \lor x = \num{a} \lor x < \num{a})\text{.}$\\
  R2 & $\vdash_{T} \neg \exists x (x < 0)\text{.}$\\
  R3 & $\text{For all }a > 0\text{, }\vdash_{T} \forall x (x < \num{a} \to (x = 0 \lor \ldots \lor x = \num{a-1}))\text{.}$\\
  R4$^{-}$ & $\text{for all }a > 0, \vdash_{T} \num{a} \ne 0$
\end{axioms}

Officially,
of course,
'<' isn't part of the language.
`$t_{1} < t_{2}$' in (R5.1)-(R6.3) is short for `$\exists z(t_{1} + s(z) = t_{2})$',
where $z$ is a suitably new variable.
(R5.1)xxx, for example, really says that $\vdash_{T} \neg \exists x \exists z(x + s(z) = 0)$.

\begin{lemma}{}{repr-mn}
  If an $n$-place function $f$ is represented in a theory $T$ by a formula $F(x_{1},\ldots,x_{n},y)$,
  then the minimization $Mn[f]$ is represented in $T$ by the formula
  \[
    F(x_{1},\ldots,x_{n},y,0) \land \forall z(z < y \to \neg F(x_{1},\ldots,x_{n},z,0)),
  \]
  provided that $T$ satisfies the conditions (R5.1), (R4.2), and (R6.3)xxx.
\end{lemma}

\begin{proof}
  Again, this proof is easier to read if we focus on the case of $n=1$;
  the general case is completely analogous.
  We have to show that the formula
  \[
    F(x,y,0) \land \forall z(z < y \to \neg F(x,z,0))
  \]
  satisfies the two conditions for representing the function $h = Mn[f]$ in $T$.
  That is,
  we have to show that whenever $h(a) = b$,
  then $T$ can prove:
  \begin{enumerate}[(i)]
    \item $F(\num{a},\num{b},0) \land \forall z(z < \num{b} \to \neg F(\num{a},z,0))$.
    \item $\forall y(F(\num{a},y,0) \land \forall z(z < y \to \neg F(\num{a},z,0)) \to y = \num{b})$.
  \end{enumerate}

  From the fact that $h = Mn[f]$ and $f(a) = b$, we know that
  $f(a,b) = 0$ and that $f(a,c) \neq 0$ for all $c < b$.
  Since $f$ is represented in $T$ by $F$,
  $T$ can prove
  \begin{equation}\tag{1}
    F(\num{a},\num{b},0)
  \end{equation}
  as well as
  \begin{equation}\tag{2}
    \forall y(F(\num{a},\num{c},y) \to y = \num{f(a,c)}),
  \end{equation}
  From (2) and R4$^{-}$,
  it follows that $T$ can prove $\neg F(\num{a},\num{c},0)$ for all $c < b$.
  By R3,
  $T$ can prove
  $\forall z(z < \num{b} \to (z = 0 \lor \ldots \lor z = \num{b-1}))$
  whenever $b > 0$.
  In that case,
  it follows that $T$ can prove
  \begin{equation}\tag{3}
    \forall z(z < \num{b} \to \neg F(\num{a},z,0)).
  \end{equation}
  For $b = 0$,
  (3) follows from R2.
  (i) is the conjunction of (1) and (3).

  For (ii).
  we show that $T$ can derive $y = \num{b}$ from
  \begin{equation}\tag{4}
    F(\num{a},y,0) \land \forall z(z < y \to \neg F(\num{a},z,0)).
  \end{equation}
  By (1), $T$ knows that $F(\num{a},\num{b},0)$.
  Together with (4), this implies $\neg (\num{b} < y)$.
  From (3) and (4), $T$ knows that $\neg (y < \num{b})$.
  By R3, $T$ can infer $y = \num{b}$.
\end{proof}

Now for the tricky part: primitive recursion.
You may want to grab a coffee.

\section{Conditions for Representability II}

Consider again the factorial function that maps
each number $n$ to $n! = 1 \cdot 2 \cdot 3 \cdots n$.
The definition by primitive recursion is simple:
\begin{align*}
  0! & = 1 \\
  (n+1)! & = (n+1) \cdot n!
\end{align*}
We need to find a formula $F(x,y)$ that expresses this function in $\L_{A}$,
so that $F(x,y)$ is true of numbers $a$ and $b$ iff $b = a!$.

The trick is to see the recursive definition of $n!$ as defining a sequence:
$0!, 1!, 2!, \ldots, n!$.
Its last (and $n+1$st) element is $n!$.
Our formula $F(x,y)$ will say that \emph{$y$ is the $x+1$st element of the sequence $0!, 1!, \ldots n!$}.

Of course,
$\L_{A}$ doesn't have terms for sequences.
But we know that sequences of numbers can be coded as single numbers.
Suppose we can find a formula $\text{Entry}(x,i,y)$
that expresses ``$y$ is the $i$th entry in the sequence coded by $x$''.
We can then define a formula $\text{fact}_n(x)$
that expresses ``$x$ codes the sequence $0!, 1!, \ldots, n!$''.
$\text{fact}_n(x)$ will say that
\begin{enumerate}[(i)]
  \item the first entry in the sequence coded by $x$ is 1, and
  \item for all $i<n$, the $(i+1)$th entry in the sequence coded by $x$ is the product of the $i$th entry and $(i+1)$.
\end{enumerate}
If we have a formula for $\text{Entry}$,
this is easily translated into $\L_{A}$.
We can then define $F(x,y)$ as
\[
  \exists z(\text{fact}_{x}(z) \land \text{Entry}(z,s(x),y)).
\]

The main task, then,
is to find a suitable formula $\text{Entry}(x,i,y)$
that holds of numbers $x,i,y$ iff
$y$ is the $i$th entry in the sequence coded by $x$.
What this formula looks like
depends on how we code sequences of numbers into single numbers.

To explain the coding method we're going to use,
assume first that
we want to code a sequence $a_{1}, a_{2}, \ldots, a_{n}$ of numbers
all of which are below 9.
We could then simply
concatenate their decimal representation:
$1,7,0,7$ would be coded as $1707$.
To simplify accessing individual elements of the sequence,
it is helpful to store the indices of the elements in the code.
For example,
if we code $1,7,0,7$ as $11273047$,
the third element could be easily identified as the digit to the right of the '3'
(in decimal representation).
As it stands,
this doesn't quite work because the indices can also be among the coded elements,
as is the case for the number 1 in the example:
there are two digits to the right of a '1'.
We can disambiguate the indices by prefixing them with yet another digit, 9,
that doesn't occur among the coded numbers.
The code of $1,7,0,7$ is now $911927930947$.
The $i$th element can be retrieved as the unique digit to the right of '$9i$'
(in decimal representation).

If we want to code arbitrary sequences numbers,
we obviously can't assume that they are all below 9.
In our real coding scheme,
we therefore code sequences not to base 10,
but to some base $p$ that it is at least 2 greater than
all numbers in the sequence and all index numbers
($p-1$ is used to mark the index numbers).
For convenience,
we'll always use a prime number as the base $p$.
The sequence $1, 12, 0$,
for example,
will be coded in base 17 as
\[
  16 \pconcatseventeen 1 \pconcatseventeen 1 \pconcatseventeen 16 \pconcatseventeen 2 \pconcatseventeen 12 \pconcatseventeen 16 \pconcatseventeen 3 \pconcatseventeen 0,
\]
where `$\pconcatseventeen$' is the operation of concatenation in base 17.
If $q$ is the code number of a sequence in base $p$,
the $i$th element of the sequence can be retrieved as
\begin{quote}
  alpha(p,q,i) = the unique number $x$, for which $(p-1) \pconcat i \pconcat x$ is part of the base-$p$ numeral of $q$.
\end{quote}
This function is expressible in $\L_{A}$.

Our present coding scheme effectively codes sequences of numbers
as \emph{pairs} of numbers $(p,q)$:
$q$ is the actual code,
but to retrieve the elements,
one also needs to know the base $p$.
We can combine $p$ and $q$ in a single number by
using the pairing function $J$ from xxx:
\[
   \textrm{J}(x,y) = \frac{\mbox{\small 1}}{\mbox{\small 2}} (x+y)(x+y+1)+y
\]

Let $L$ and $R$ be functions that extract the elements of a pair encoded by $J$,
so that $L(J(x,y)) = x$ and $R(J(x,y)) = y$.
If we have coded a sequence of numbers $a_{1},\ldots,a_{n}$ by
$p$ and $q$ as described above,
and packaged these into a single number $c = \textrm{J}(p,q)$,
we can retrieve any element $a_{i}$ of the doubly coded sequence as
\[
  \text{beta}(c,i) = \text{alpha}(\textrm{L}(c),\textrm{R}(c),i).
\]
This function is also expressible in $\L_{A}$.
That is,
there is a formula $\text{Beta}(x,i,y)$
that holds of $x,i,y$ iff $y$ is the $i$th element of the sequence (doubly) coded by $x$.
This is formula $\text{Entry}(x,i,y)$ that we were looking for.

I'm not going to write down the $\L_{A}$-formula $\text{Beta}(x,i,z)$.
Instead,
I'll show that
$\text{beta}$ can be defined by certain operations from
functions and relations that are obviously expressible in $\L_{A}$.
This will allow us to see not only that
$\text{beta}$ is expressible in $\L_{A}$,
but also that it is representable in any sufficiently strong theory $T$.

Above,
I already defined beta by composition from $\text{alpha}$, $L$ and $R$.
$L$ and $R$ can be defined by minimization and bounded quantification from $J$ and identity:

\begin{eqnarray*}
  \textrm{L}(q) &=& \mu x\, \exists y\!\le\!q(\textrm{J}(x,y)=q) \\
  \textrm{R}(q) &=& \mu y\, \exists x\!\le\!q(\textrm{J}(x,y)=q)
\end{eqnarray*}

$J$ can be defined by composition and regular minimization from addition, multiplication, and identity
(and the constants 1 and 2,
which can defined from s and 0):

\[
   \textrm{J}(x,y) = \mu z \, (2 \cdot z = (x+y) \cdot (x+y+1) + 2\cdot y).
\]

It remains to define $\text{alpha}$.
Here is a more explicit version of the definition given above:

\begin{eqnarray*}
  \text{alpha}(p,q,i) &=& \mu x\, ((p \dotminus 1) \pconcat i \pconcat x\,\,\mbox{is part$_{p}$ of}\,\, q).
\end{eqnarray*}

`$x \,\mbox{is part$_{p}$ of}\, y$' means
`the base-$p$ numeral of $x$ is part of the base-$p$ numeral of $y$',
and '$\dotminus$' is truncated subtraction,
defined as follows:
\begin{eqnarray*}
  x \dotminus y &=& \mu z\, ((y\!<\!x \,\to\, y\!+\!z\!=\!x) \,\land\, (\neg(y\!<\!x) \,\to\, z\!=\!0)) \\
  x < y &\Leftrightarrow& \exists z\!\le\!y (x + s(z) = y).
\end{eqnarray*}

The part$_{p}$ relation can be defined in terms of base-$p$ concatenation:

\begin{eqnarray*}
  x \,\mbox{is part$_{p}$ of}\, y &\Leftrightarrow& \exists v\!\le\!y \, \exists w\!\le\!y \, (v \pconcat x \pconcat w = y \,\lor\, v \pconcat x = y \, \\
  && \lor\, x \pconcat v = y \, \lor \, x \!=\! y)
\end{eqnarray*}

To define base-$p$ concatenation,
we use the function $\eta(p,x)$
that returns the smallest power of $p$  greater than $x$.
That is,
$\eta(p,x)$ is the next-greater number after $x$ whose base-$p$ numeral
is longer than the base-$p$ numeral of $x$.

\begin{eqnarray*}
  x \pconcat y &=& x \cdot \eta(p,y) +y \\
  \eta(p,x) &=& \mu y\,((y\,\,\mbox{is power of prime}\,\, p \\
               && \,\land\, \, y\!>\!x \,\land\, y\!>\!1) \, \lor \,  (\neg(p\,\,\mbox{is prime}) \,\land\, y\!=\!0))
\end{eqnarray*}

Finally, we define `$x$ is power of $p$' and `$x$ is prime':

\begin{eqnarray*}
  x\,\,\mbox{is power of prime}\,\,p &\Leftrightarrow& x\!\not=\!0 \,\land\,
   p\,\,\mbox{is prime} \\
   && \land\, \forall y\!\le\!x\, (y\,\,\mbox{divides}\,\,x
   \,\to\, y\!=\!1 \,\lor\, p\,\,\mbox{divides}\,\,y) \\
  x\,\,\mbox{is prime} &\Leftrightarrow& x \ne 0 \text{ and } x \ne 1 \text{ and } \forall
    y\!<\!x\,(y\,\,\mbox{divides}\,\,x \,\to\, y\!=\!1 \,\lor\, y\!=\!x) \\
  x\,\,\mbox{divides}\,\,y &\Leftrightarrow& \exists z\!\le\!y\,(y=x\cdot z)
\end{eqnarray*}

In all these definitions,
new functions are always defined from old functions by composition and minimization,
and new relations by bounded quantification and boolean combination.
Some functions and relations are left undefined:
addition, multiplication, identity, and the constants 0, 1, 2.
These are obviously expressible in $\L_{A}$.
To ensure that they are also representable in a theory $T$,
we have to assume that $T$ satisfies the following conditions:

\begin{axioms}
  R4 & $\text{For all }a, b\text{, if }a \neq b\text{ then }\vdash_{T} \num{a} \neq \num{b}\text{.}$\\
  R5 & $\text{For all }a, b\text{, }\vdash_{T} \num{a} + \num{b} = \num{a+b}\text{.}$\\
  R6 & $\text{For all }a, b\text{, }\vdash_{T} \num{a} \cdot \num{b} = \num{a\cdot b}\text{.}$
\end{axioms}

\begin{lemma}{}{identity-repr}
   The identity relation is represented by $x=y$ in every theory $T$ that satisfies R4.
\end{lemma}
\begin{proof}
  We need to show that for all $a,b$:
  \begin{enumerate}[(i)]
    \item if $a = b$ then $\vdash_{T} \num{a} = \num{b}$.
    \item if $a \neq b$ then $\vdash_{T} \neg (\num{a} = \num{b})$.
  \end{enumerate}
  (i) holds in any theory because $\num{a}$ and $\num{b}$ are the same term.
  (ii) holds by R4.
\end{proof}

\begin{lemma}{}{plus-repr}
   The addition function is represented by $x+y=z$ in every theory $T$ that satisfies R5.
\end{lemma}
\begin{proof}
  Condition (i) in the definition of representation is given by R5.
  Condition (ii) is a theorem of the predicate calculus.
\end{proof}

\begin{lemma}{}{times-repr}
  The multiplication function is represented by $x\cdot y=z$ in every theory $T$ that satisfies R6.
\end{lemma}
\begin{proof}
  Condition (i) in the definition of representation is given by R6.
  Condition (ii) is a theorem of the predicate calculus.
\end{proof}

\begin{lemma}{}{repr-closure-bounded}
  Assume that $T$ satisfies R2, R3, and R5,
  and an $n+1$-ary relation $R$ is represented in $T$ by a formula $A(x_{1},\ldots,x_{n},y)$.
  Then for all $k$,
  the $n$-ary relation $\forall y < k R(x_{1},\ldots,x_{n},y)$
  is represented in $T$ by $\forall y (y < \num{k} \to A(x_{1},\ldots,x_{n},y))$,
  and $\exists y < k R(x_{1},\ldots,x_{n},y)$
  by $\exists y (y < \num{k} \land A(x_{1},\ldots,x_{n},y))$.
\end{lemma}
\begin{proof}
  As usual, I'll focus on the case of $n=1$ for readability.
  For the universal quantifier,
  we have to show that $\forall y(y < \num{k} \to A(\num{a},y))$ satisfies the two representation conditions for relations:
  \begin{enumerate}[(i)]
    \item if $\forall y < k R(a,y)$ then
      $\vdash_{T} \forall y (y < \num{k} \to A(\num{a},y))$,
    \item if $\neg \forall y < k R(a,y)$ then
      $\vdash_{T} \neg \forall y (y < \num{k} \to A(\num{a},y)$.
  \end{enumerate}

  For (i), assume $\forall y < k R(a,y)$.
  We first consider the case where $k > 0$.
  Since $A$ represents $R$ in $T$,
  $T$ can prove $A(\num{a},\num{b})$ for all $b < k$.
  So $T$ can prove $\forall y(y\!=\!\num{b} \to A(\num{a},y))$ for all $b < k$.
  By R3,
  $T$ can prove $\forall y (y < \num{k} \to (y = 0 \lor \ldots \lor y = \num{k-1}))$.
  So $T$ can prove $\forall y (y < \num{k} \to A(\num{a},y))$.
  For $k = 0$,
  $T$ can prove $\neg \exists y (y < 0)$ by R2,
  which entails $\forall y (y < 0 \to A(\num{a},y))$.

  For (ii), assume $\neg \forall y < k R(a,y)$.
  Then there is some $b < k$ such that $\neg R(a,b)$.
  Since $A$ represents $R$,
  $T$ can prove $\neg A(\num{a},\num{b})$.
  Pick any $c$ with $k = b+(c+1)$.
  By R5,
  $T$ can prove $\num{b} + \num{c+1} = \num{k}$.
  Since $T$ can also prove $\num{c+1} = s(\num{c})$
  (because the two sides are the same term),
  $T$ can prove $\num{b} + s(\num{c}) = \num{k}$
  and thus also $\num{b} < \num{k}$,
  which is short for $\exists z(\num{b} + s(z) = \num{k})$.
  Hence $T$ can prove $\exists y (y < \num{k} \land \neg A(\num{a},y))$,
  which is equivalent to $\neg \forall y (y < \num{k} \to A(\num{a},y)$.

  The proof for $\exists y < k R(x_{1},\ldots,x_{n},y)$ is analogous.
\end{proof}

% It follows that x<y is representable as ∃z(∃v(z+s(v)=y) ∧ x+s(z)=y) in any
% theory that satisfies R1-R6.

\begin{lemma}{}{repr-closure-boolean}
  If two $n$-ary relations $R_{1}$ and $R_{2}$ are represented in a theory $T$
  by formulas $A_{1}$ and $A_{2}$, respectively,
  then $A_{1} \land A_{2}$ represents the conjunction of $R_{1}$ and $R_{2}$ in $T$
  $A_{1} \lor A_{2}$ represents the disjunction of $R_{1}$ and $R_{2}$ in $T$
  and $\neg A_{1}$ represents the negation of $R_{1}$ in $T$.
\end{lemma}
\begin{proof}
  Let's look at the case for conjunction, assuming $n=1$.
  We have to show that
  \begin{enumerate}[(i)]
    \item if $R_{1}(a)$ and $R_{2}(a)$,
    then $\vdash_{T} A_{1}(\num{a}) \land A_{2}(\num{a})$;
    \item if it is not the case that $R_{1}(a)$ and $R_{2}(a)$,
    then $\vdash_{T} \neg (A_{1}(\num{a}) \land A_{2}(\num{a}))$.
  \end{enumerate}

  For (i),
  assume $R_{1}(a)$ and $R_{2}(a)$.
  By the assumption that $A_{1}$ and $A_{2}$ represent $R_{1}$ and $R_{2}$,
  $T$ can prove $A_{1}(\num{a})$ and $A_{2}(\num{a})$.
  Then $T$ can also prove their conjunction.

  For (ii),
  assume it is not the case that $R_{1}(a)$ and $R_{2}(a)$.
  By the assumption that $A_{1}$ and $A_{2}$ represent $R_{1}$ and $R_{2}$,
  $T$ can prove $\neg A_{1}(\num{a})$ or $\neg A_{2}(\num{a})$.
  Either way, $T$ can prove their disjunction.

  The other cases are similarly trivial.
\end{proof}

Together,
these lemmas show that beta is representable in any theory $T$
that satisfies R2--R6,
where R4 subsumes R4$^{-}$.

\begin{lemma}{Beta-function Lemma}{beta}
  There is a function $\text{beta}$ such that
  for any finite sequence $a_{1}, \ldots, a_{n}$ of natural numbers,
  there is a number $c$ such that
  $\text{beta}(c,i) = a_{i}$ for all $1 \leq i \leq n$.
  Moreover,
  beta is representable in any theory $T$ that satisfies R1--R6.
\end{lemma}
\begin{proof}
  I've explained above how this function $\text{beta}$ can be defined
  by composition, minimization, bounded quantification, and boolean combination
  from addition, multiplication, identity, and the successor function.
  By lemmas \ref{lem:s-repr}, \ref{lem:identity-repr}, \ref{lem:plus-repr}, \ref{lem:times-repr},
  this basis is representable in any theory $T$ that satisfies R1--R6.
  By lemma \ref{lem:repr-closure-composition}, \ref{lem:repr-closure-minimization},
  \ref{lem:repr-closure-bounded}, and \ref{lem:repr-closure-boolean},
  representability in any such $T$ is closed under
  composition, minimization, bounded quantification, and boolean combination.
\end{proof}

With this, we can prove our final lemma.

\begin{lemma}{}{repr-closure-pr}
  If $h$ is defined from an $f$ and $g$ by primitive recursion,
  and $f$ and $g$ are representable in a theory $T$ that satisfies R1--R6,
  then $h$ is also representable in $T$.
\end{lemma}
\begin{proof}
  Assume that $h = Pr[f,g]$,
  meaning that
  \begin{align*}
    h(x_{1},\ldots,x_{n},0) & = f(x_{1},\ldots,x_{n}) \\
    h(x_{1},\ldots,x_{n},n+1) & = g(x_{1},\ldots,x_{n},n,h(x_{1},\ldots,x_{n},n)).
  \end{align*}
  For readability, I assume that $n=1$.

  With the help of the beta function lemma,
  it's not hard to construct a formula $S(c,x,k)$
  for ``$c$ codes the sequence $h(x,0), h(x,1), \ldots, h(x,k)$''.
  We could then define $H(x,y,z)$ as $\exists c(S(c,x,y) \land \text{Beta}(c,y,z))$,
  and show that $H$ represents $h$ in $T$.

  But let's take a shortcut.
  Let $\text{Seq}$ be the \emph{relation}
  that holds between numbers $c,x,k$
  iff $c$ codes the sequence $h(x,0), \ldots, h(x,k)$.
  This can be defined from $f$, $g$, and $\text{beta}$
  by boolean combination and bounded quantification:
  \[
    \text{Seq}(c,x,k) = \text{beta}(c,1) = f(x) \text{ and } \forall i \leq k(\text{beta}(c,i+1) = g(x,i,\text{beta}(c,i))).
  \]
  By the assumption that $f$ and $g$ are representable in $T$
  and lemmas \ref{lem:beta}, \ref{lem:repr-closure-bounded} and \ref{lem:repr-closure-boolean},
  $\text{Seq}$ is representable in $T$.
  By lemma \ref{lem:repr-closure-mn},
  so is the function
  \[
    d(x,k) = \mu c \, \text{Seq}(c,x,k)
  \]
  that returns the code of $h(x,0), \ldots, h(x,k)$.
  From this,
  we can define $h$ by composition, projection, and successorhood:
  \[
    h(x,k) = \text{beta}(d(x,k),s(k)).
  \]
  By lemmas \ref{lem:closure-s}, \ref{lem:repr-closure-composition} and \ref{lem:repr-closure-projection},
  $h$ is representable in $T$.
\end{proof}

\begin{theorem}{}{recrep}
  All total recursive functions are representable in any theory that satisfies R1--R6.
\end{theorem}
\begin{proof}
  By induction on the definition of total recursive functions,
  using lemmas \ref{lem:s-repr}, \ref{lem:zero-repr}, \ref{lem:plus-repr}, \ref{lem:times-repr},
  \ref{lem:repr-closure-composition}, \ref{lem:repr-closure-minimization}, and \ref{lem:repr-closure-pr}.
\end{proof}

\begin{corollary}{}{recrelrep}
  All recursive relations are representable in any theory that satisfies R1--R6.
\end{corollary}
\begin{proof}
  By the theorem,
  the lemma on characteristic functions,
  and the fact that any theory $T$ that satisfies R6 can prove $0 \neq 1$.
\end{proof}

\begin{corollary}
  All recursive functions and relations are expressible in $\L_{A}$.
\end{corollary}
\begin{proof}
  Exercise.
\end{proof}

\begin{exercise}
  Explain why all recursive functions and relations are expressible in $\L_{A}$,
  given theorem \ref{recrep} and corollary \ref{recrelrep}.
\end{exercise}


\section{Representations}

Let's reflect on what we've achieved.
We've shown that all recursive functions are representable in any theory
that knows a few facts about the natural numbers,
summarized in R1--R6.

\begin{axioms}
  R1 & $\neg \exists x (x < 0)$\\
  R2 & $\text{For all }a > 0\text{, }\vdash_{T} \forall x (x < \num{a} \to (x = 0 \lor \ldots \lor x = \num{a-1}))\text{.}$\\
  R3 & $\text{For all }a\text{, }\vdash_{T} \forall x (\num{a} < x \lor x = \num{a} \lor x < \num{a})\text{.}$\\
  R4 & $\text{For all }a, b\text{, }\vdash_{T} \num{a} + \num{b} = \num{a+b}\text{.}$\\
  R5 & $\text{For all }a, b\text{, }\vdash_{T} \num{a} \cdot \num{b} = \num{a\cdot b}\text{.}$\\
  R6 & $\text{For all }a, b\text{, if }a \neq b\text{ then }\vdash_{T} \num{a} \neq \num{b}\text{.}$
\end{axioms}

Each of R1-R6 specifies one or more sentences that must be contained in T.
As such,
R1-R6 can be seen as an axiomatization of a theory.
This theory is not especially elegant,
especially if we were to unpack the '<' relation in R1-R3.
An elegant alternative that satisfies R1-R6 is the theory Q,
also known as Robinson arithmetic.
It has the following seven axioms.

\begin{align}
  \text{\textbf{Q1.}} \quad &\forall x\forall y\, (s(x)\!=\!s(y) \,\to\, x\!=\!y) \\
  \text{\textbf{Q2.}} \quad &\forall x \, 0\! \not= \!s(x) \\
  \text{\textbf{Q3.}} \quad &\forall x \,(x\!\not= 0 \,\to\, \exists y\, x\!=\!s(y))\\
  \text{\textbf{Q4.}} \quad &\forall x(x + 0 = x) \\
  \text{\textbf{Q5.}} \quad &\forall x\forall y\, (x + s(y) = s(x + y)) \\
  \text{\textbf{Q6.}} \quad &\forall x(x \cdot 0 = 0) \\
  \text{\textbf{Q7.}} \quad &\forall x\forall y\, (x \cdot s(y) = (x \cdot y) + x).
\end{align}

Axioms Q4-Q7 are the recursive definitions of addition and multiplication.
Q1-Q3 say something about the structure of the natural numbers.

Connection to PA.

Q is fairly weak.
E.g., it can't prove $\forall x (x+y = y +x)$, or $\forall x (x \not= s(x))$.
But it can represent all recursive functions and relations.

\begin{theorem}{}{Q-rep}
  All recursive functions are representable in Q.
\end{theorem}
\begin{proof}
  We need to show that Q is robinsonian.
\end{proof}

PA is clearly stronger than Q, and therefore also robinsonian.

exercise...

******

We also have a converse:

Theorem: any relation that's representable in any axiomatizable and consistent $\L_{A}$-theory is recursive.

Proof with Church's Thesis:
Assume $A(x_{1},\ldots,x_{n})$ represents $R$ in an axiomatizable and consistent $\L_{A}$-theory $T$.
This means that if $R$ holds of some numbers $a_{1},\ldots,a_{n}$,
then $T$ can prove $A(\num{a_{1}},\ldots,\num{a_{n}})$,
and if $R$ does not hold of $a_{1},\ldots,a_{n}$,
then $T$ can prove $\neg A(\num{a_{1}},\ldots,\num{a_{n}})$.
Now one can computably enumerate all (codes of) theorems of $T$.
To check whether $R$ holds of some numbers $a_{1},\ldots,a_{n}$,
we can wait until either $A(\num{a_{1}},\ldots,\num{a_{n}})$ or $\neg A(\num{a_{1}},\ldots,\num{a_{n}})$ appears on this list.

We know that r.e. relations result from recursive relations by existential quantification.
Now remember that an $n$-ary relation $R$ is r.e. iff
there is an $n-1$-ary recursive relation $Q$ such that
$R(a_{1},\ldots,a_{n})$ iff $\exists y Q(a_{1},\ldots,a_{n},y)$.
It follows that $\L_{A}$ can express all r.e. relations.
But we also know that not all r.e. relations are recursive.
It follows that $\L_{A}$ can express more than just the recursive relations.

It follows that the complete truth of $\L_{A}$ is not computably axiomatizable!
This is a version of Gödel's Incompleteness Theorem.

******

At the beginning of section xx,
I asked about definability.
I announced that all recursive functions and relations are definable in the language of arithmetic $\L_{A}$.
Can you see why this holds?

Theorem: all recursive functions and relations are definable in $\L_{A}$.

Proof: All axioms of R and Q are evidently true in the standard model of arithmetic.
It follows that the formulas that represent recursive functions in Q
(and any other robinsonian theory)
also define those functions.

We've just seen that
the converse does not hold.
Some relations that are definable in $\L_{A}$ are not recursive.
That's because the recursive relations aren't closed under existential quantification.
They also aren't closed under universal quantification.

One can define a whole hierarchy of relations
expressible in $\L_{A}$,
in terms of the quantifiers used in their definitions.
At the bottom of the hierarchy are the relations expressible by
formulas without any unbounded quantifiers
(except for the quantifier that occurs in the definition of $<$;
for this purpose,
it is cleaner to add '$<$' as a primitive relation to $\L_{A}$).
These are called $\Delta_{0}$-formulas,
and the relations $\Delta_{0}$-relations.
At the next level are two classes of relations:
the $\Sigma_{1}$-relations are defined by
($\Sigma_{1}$-)formulas that prefix existential quantifiers to $\Delta_{0}$-formulas,
the $\Pi_{1}$-relations are defined by
($\Pi_{1}$-)formulas that prefix universal quantifiers to $\Delta_{0}$-formulas.
Prefixing universal quantifiers to a $\Sigma_{1}$-formula yields a $\Pi_{2}$-formula;
prefixing existential quantifiers to a $\Pi_{1}$-formula yields a $\Sigma_{2}$-formula.
These define the $\Sigma_{2}$-relations and the $\Pi_{2}$-relations, respectively.
And so on.
The recursive relations,
it turns out,
are all $\Sigma_{1}$:
they can be expressed by formulas that prefix existential quantifiers to $\L_{A}$-formulas
without unbounded quantifiers.

[It's useful to think of
this hierarchy not so much in terms of language,
but in terms of relations.
We start with the computable relations $\Delta_{0}$,
then consider relations defined by existential or universal quantification from them,
and so on.]


In fact,
we know more about what a representation of recursive relations in $\L_{A}$ looks like.
Note that every term of $\L_{A}$ expresses a polynomial:
it is (arithmetically) equivalent to an expression of the form
$a_{0} + a_{1} \cdot x + a_{2} \cdot x^{2} + \ldots + a_{n} \cdot x^{n}$.
Since the only predicate in $\L_{A}$ is equality,
all atomic $\L_{A}$-formulas express equations between polynomials.
It follows that any relation that is expressible in $\L_{A}$ can
be defined from an equation between polynomials by logical operations.
Now,
one can show that all recursive relations (and therefore also all r.e. relations)
are definable in $\L_{A}$ by formulas that prefix existential quantifiers to an equation between polynomials.
This is the result of the so-called MRDP Theorem,
named after Matiyasevich, Robinson, Davis, and Putnam.
The proof is much too difficult to be included here.

\begin{exercise}
  Say that a relation $R$ is \emph{weakly represented} by an $\L_{A}$-formula $A(x_{1},\ldots,x_{n})$ in a theory $T$ iff for all numbers $a_{1},\ldots,a_{n}$,
  \[
    R(a_{1},\ldots,a_{n}) \text{ iff } \vdash_{T} A(\num{a_{1}},\ldots,\num{a_{n}}).
  \]
  Explain the following facts:
  \begin{enumerate}[(a)]
    \item A relation can be weakly represented in $T$ without being strongly represented in $T$.
    \item If $R$ is weakly represented in an axiomatizable and consistent theory, then it is r.e.
    \item All recursive relations are weakly represented in any $\L_{A}$-theory that is   consistent with Q.
    (Hint:
    We know that each recursive relation $R$ is represented in Q by some formula $A$.
    Let $\hat{Q}$ be the conjunction of the seven axioms of Q,
    and consider the formula $\hat{Q} \to A$.)
  \end{enumerate}
\end{exercise}

\iffalse

We can ask what Q knows about the numbers. Does it know that 2+2=4? Yes. It knows all atomic facts about addition and multiplication.

It means that Q can prove all true $\mathrm{\Delta}_{0}$ sentences.
(And so also all true $\mathrm{\Sigma}_{0}$ sentences.)

\fi



%%% Local Variables:
%%% mode: latex
%%% TeX-master: "logic3.tex"
%%% End:
