\setcounter{chapter}{7}
\chapter{Arithmetical Representability}\label{ch:representability}

In this chapter,
we'll show that
all computable functions and relations on the natural numbers
can be defined in the language $\L_A$ of arithmetic.
We'll also show that
these functions and relations
are ``representable'' in moderately strong theories of arithmetic like Q and PA.
As foreshadowed at the end of Chapter~\ref{ch:computability},
it will follow that
there can be no true, computably axiomatizable, and complete theory of arithmetic.
Further limitative consequences will be explored in the next two chapters.

\section{Definability}\label{sec:definability}

In Section~\ref{sec:arithmetic},
I introduced the language $\L_{A}$ of arithmetic,
with non-logical symbols for 0 (`0'),
the successor function (`$s$'), addition (`$+$'), and multiplication (`$\times$').
I mentioned that other arithmetical concepts can be defined in terms of these primitives.
For example,
we can define the less-than relation $<$ by stipulating that
for any terms $t_{1}$ and $t_{2}$,
`$t_{1} < t_{2}$' is short for `$\exists z (t_1 + s(z) = t_2)$',
where $x$ is a variable not occurring in $t_1$ or $t_2$.
This works because the relation $<$ holds between natural numbers $a$ and $b$
iff there is a non-zero number $c$ such that $a + c = b$.
The formula $\exists z(x + s(z) = y)$,
with free variables $x$ and $y$,
effectively expresses this relation:
whenever we replace $x$ and $y$ by terms $t_1,t_2$ for numbers,
the resulting sentence is true (in the standard model of arithmetic $\Mod{A}$) iff
the number denoted by $t_1$ is less than the number denoted by $t_2$.

Every natural number has a canonical term in $\L_{A}$,
which we call its \emph{$\L_{A}$-numeral}.
The $\L_A$-numeral of $0$ is `0',
the $\L_A$-numeral of $1$ is `$s(0)$',
and so on.
It will be useful to have an abbreviation.
I'll use `$\num{n}$' as a shorthand for the $\L_{A}$-numeral of the number $n$.
So `$\num{2} + \num{3} = \num{5}$' abbreviates
`$s(s(0)) + s(s(s(0))) = s(s(s(s(s(0)))))$'.
Since every $\L_A$-term denotes (in $\Mod{A}$) a number
that is also denoted by an $\L_A$-numeral $\num{n}$,
we can focus our attention on $\L_A$-numerals
when discussing definability.
We'll say that the formula
$\exists z(x + s(z) = y)$ \emph{defines} the less-than relation $<$ because
for all natural numbers $a$ and $b$,
$a<b$ iff
$\exists z(\num{a} + s(z) = \num{b})$ is true (in the standard model $\Mod{A}$).
In general:

\begin{definition}{}{defines-relation}
  An $\L_{A}$-formula $A(x_{1},\ldots,x_{n})$ \emph{defines} an $n$-place relation $R$ on $\mathbb{N}$ iff,
  for all numbers $a_{1},\ldots,a_{n}$,
  $A(\num{a_{1}},\ldots,\num{a_{n}})$ is true in $\Mod{A}$ iff $a_{1},\ldots,a_{n}$ stand in the relation $R$.
\end{definition}

\begin{exercise}
  Give two other $\L_A$-formulas that defines the less-than relation, and explain why they do so.
\end{exercise}

[Possible exercise: even]

We can also define further functions in $\L_{A}$,
besides the successor, addition, and multiplication functions.
It's important to clarify what kind of definition we are after.
In the previous chapter,
we spoke of ``definitions by primitive recursion''.
The factorial function, for example, can be recursively defined by the following clauses:
\begin{align*}
  0! & = 1 \\
  s(x)! & = s(x) \times x!.
\end{align*}
But these clauses don't give us a way to
express statements about factorials in $\L_{A}$.
Ideally,
we'd like to find an $\L_{A}$-term $f(x)$
so that $f(\num{a})$ denotes $a!$,
for all natural numbers $a$.
There is no such term,
however.
Still,
we can find what in Section~\ref{sec:zfc} I called a ``syncategorematic'' definition.
We can find a formula $F(x,y)$
such that
$F(\num{a},\num{b})$ is true (in $\Mod{A}$) iff $b = a!$.
With the help of this formula,
any statements about factorials can be translated into $\L_{A}$.
For example,
we can translate $\forall x(x < x!)$ into
\[
  \forall x \forall y(F(x,y) \to x < y).
\]

\begin{definition}{}{defines-function}
  An $\L_{A}$-formula $A(x_{1},\ldots,x_{n},y)$ \emph{defines} a (total) $n$-ary function $f$ on $\mathbb{N}$ iff,
  for all numbers $a_{1},\ldots,a_{n},b$,
  $A(\num{a_{1}},\ldots,\num{a_{n}},\num{b})$ is true in $\Mod{A}$ iff
  $f(a_{1},\ldots,a_{n}) = b$.
\end{definition}

(We won't be interested in non-total functions in this chapter.)

We say that a relation or function is \emph{definable} in $\L_{A}$ if
it is defined by some formula in $\L_{A}$.

\begin{exercise}
  Give an $\L_A$-expression that defines the addition function.
\end{exercise}

\begin{exercise}
  Give an $\L_{A}$-formula that defines the switcheroo function $\delta$
  that maps any positive number to 0 and 0 to 1.
\end{exercise}

We'll show that all recursive functions are definable in $\L_{A}$.
Since a relation is recursive iff its characteristic function is recursive,
it will follow that
all recursive relations are expressible in $\L_{A}$.

% We'll use the obvious induction strategy.
% First,
% we'll first show that
% the base functions (zero, successor, and projection) are expressible in $\L_{A}$.
% Then,
% we'll show that
% if some functions are expressible in $\L_{A}$
% then so are any functions definable from them by composition, primitive recursion, and regular minimization.

It's not at all obvious that
all recursive functions are definable in $\L_{A}$.
Try to define the factorial function in terms of $+$, $\times$, $s$, and $0$!
We know that a function is recursive iff
there is some algorithm for computing the output for any given input.
It's surprising that any such algorithm
can be built out of algorithms for addition and multiplication.

Consider,
for example,
the relation that holds between the code number of a Turing machine $M$,
an ``input'' number $n$,
and a number $k$
iff $M$ halts on input $n$ within $k$ steps.
This relation is computable:
we can simply run $M$ on input $n$ for $k$ steps,
and return `yes' if $M$ has halted by then,
and `no' otherwise.
Since all recursive relations are definable in $\L_A$,
there is an $\L_A$-expression $A(x,y,z)$ such that
$A(\num{m},\num{n},\num{k})$ is true (in $\Mod{A}$) iff
the Turing machine coded by $m$ halts on input $n$ within $k$ steps.
From this,
we quickly get a version of Gödel's incompleteness theorem:
$\exists z A(x,y,z)$ is true (in $\Mod{A}$) iff
the Turing machine coded by $x$ halts on input $y$.
This is an $\L_{A}$-expression whose instances can't be decided by any algorithm.
So there can be no complete axiomatic theory that decides all its instances.

Gödel's own proof of incompleteness involved a different relation.
Remember that proofs from computable axioms are ``verifiable''.
There is an algorithm for checking that something is a proof.
We've already seen that
algorithms can generally be represented as operating on numbers,
with a suitable coding and decoding of the inputs and outputs.
We can code each $\L_{A}$-sentence and each sequence of $\L_{A}$-sentences by a number,
called the gn.
Since there is an algorithm
for checking whether a sequence is a proof of some target sentence,
it follows by Church's Thesis that
the relation Prf(x,y) is recursive,
and so represented by a formula $Prf(x,y)$.
We can then construct a formula $Prov(y)$ as $\exists x Prf(x,y)$
that expresses provability.
Gödel showed that
we can then construct another $\L_{A}$-formula $G$ that is true iff
$\neg Prov(x)$ is true of $G$.
That is,
we'll find an arithmetical sentence $G$ that is true iff it is not provable.

Now suppose $G$ is provable,
in some computably axiomatized theory $T$.
Then $G$ is false,
as it is true iff it is not provable.
So if an arithmetical theory $T$ doesn't prove false sentences,
then it can't prove $G$.
In this case,
$G$ is true.
So $T$ can't prove its negation either,
as the negation is false.
So any sound (computably axiomatized) $\L_{A}$-theory is incomplete.

These are ``semantic'' versions of Gödel's incompleteness theorem.
They rely on the concept of truth in the standard model of arithmetic,
Gödel's original proof was ``syntactic''.
It relied not on definability in $\L_{A}$
but on a related concept of representability.

\begin{exercise}
  Explain why every finite set is definable in $\L_{A}$.
\end{exercise}

\begin{exercise}
  Explain why the Busy Beaver function $\Sigma$ is definable in $\L_{A}$.
  (Hint: consider the relation $H$ that holds between
  four numbers $m$, $n$, $t$, $k$ iff $m$ codes a Turing machine with $n$ states
  that halts, on blank input, after $t$ steps leaving $k$ strokes on the tape.)
  % \Sigma(n) = k iff $\exists m \exists t (H(m,n,t,k) \land \forall m' \forall k' \forall t' (H(m',n,t',k') \to k' \leq k))$.
\end{exercise}


\section{Representability}\label{sec:representability}

In the previous section,
I appealed to the standard model of arithmetic.
`$+$', `$\times$', `$s$' and `0' are non-logical symbols.
They have an \emph{intended interpretation},
but this interpretation isn't built into the language.
An axiomatic $\L_{A}$-theory doesn't automatically ``know'' what the non-logical symbols mean.
Just because `$\num{1}+\num{2}=\num{3}$' is true,
on the intended interpretation,
doesn't mean that an axiomatic theory can prove `$\num{1} + \num{2} = \num{3}$'.
The theory axiomatized by the empty set of axioms, for example, can't prove this.

Exercise: exhibit a theory that can prove `$\num{1} + \num{2} \ne \num{3}$'.

The standard axiomatic theory of arithmetic,
Peano Arithmetic (PA),
can prove `$\num{1} + \num{2} = \num{3}$',
Indeed,
for any numbers $a,b,c$
if $a+b=c$ then
PA contains `$\num{a} + \num{b} = \num{c}$',
In that sense,
PA ``knows'' all particular facts about addition:
it knows that $1+2=3$, that $127+349=476$, and so on.

Similarly,
PA knows all particular facts about the less-than relation:
whenever $a < b$,
PA contains $\num{a} < \num{b}$,
whenever $a \not< b$,
PA contains $\neg(\num{a} < \num{b})$.
Of course,
`$<$' isn't really part of the language.
What I really mean is that
whenever $a < b$ then
PA contains $\exists z(\num{a} + s(z) = \num{b})$,
and whenever $a \not< b$ then
PA contains $\neg\exists z(\num{a} + s(z) = \num{b})$.
We say that
$\exists z(x + s(z) = y)$ \emph{represents} the less-than relation in PA.
In general:

\begin{definition}{}{repr-relation}
    An $\L_{A}$-formula $A(x_{1},\ldots,x_{n})$ \emph{represents} an $n$-ary relation $R$ on $\mathbb{N}$ in a theory $T$ iff, for all numbers $a_{1},\ldots,a_{n}$,
    \begin{cenumerate}
    \item[(i)] if $R$ holds of $a_{1},\ldots,a_{n}$, then $\proves_{T} A(\num{a_{1}},\ldots,\num{a_{n}})$, and
    \item[(ii)] if $R$ does not hold of $a_{1},\ldots,a_{n}$, then $\proves_{T} \neg A(\num{a_{1}},\ldots,\num{a_{n}})$.
    \end{cenumerate}
\end{definition}
  
If a relation is represented in a theory $T$ by some formula,
we say that it is \emph{representable} in $T$.

We can also apply this to functions.
We'll say that $x+y=z$ represents the addition function in PA.
In general:

\begin{definition}{}{repr-function}
    An $\L_{A}$-formula $A(x_{1},\ldots,x_{n},y)$ \emph{represents} a (total) $n$-ary function $f$ on $\mathbb{N}$ in $T$ iff, for all numbers $a_{1},\ldots,a_{n}$,
    \begin{cenumerate}
    \item[(i)] $\proves_{T} A(\num{a_{1}},\ldots,\num{a_{n}},\num{f(a_{1},\ldots,a_{n})})$, and
    \item[(ii)] $\proves_{T} \forall y(A(\num{a_{1}},\ldots,\num{a_{n}},y) \to y = \num{f(a_{1},\ldots,a_{n})})$.
    \end{cenumerate}
\end{definition}


A more direct analog of condition (ii) for relations would be to require that
\begin{cenumerate}
  \item[(ii$'$)] if $b \not= f(a_{1},\ldots,a_{n})$, then $\proves_{T} \neg A(\num{a_{1}},\ldots,\num{a_{n}},\num{b})$.
\end{cenumerate}
Our condition (ii) is strictly stronger than this.
It effectively requires $T$ to know that $A(x_{1},\ldots,x_{n},y)$
expresses a functional relationship
(as discussed in Section~\ref{sec:zfc}).

To illustrate what these clauses do,
return to the example of the factorial.
What do we need for a formula $F(x,y)$ to represent the factorial function in a theory $T$?
Condition (i) requires that
whenever $b = a!$,
then $\proves_{T} F(\num{a},\num{b})$.
This leaves open that
$T$ also proves $F(\num{a},\num{c})$ for some $c \not= b$.
Indeed,
the formula $x\!=\!x \land y\!=\!y$ passes condition (i)
in any theory $T$,
But there's no good sense in which this formula represents the factorial function.
Condition (ii$'$) require that
if $b \not= a!$
then $\proves_{T} \neg F(\num{a},\num{b})$.
That is,
there must be no other number of which $T$ believes that it is the factorial of $a$.
Our stronger condition (ii) demands that
$T$ must know that there is no other such number.

\begin{proposition}{}{repr-def}
  If an $\L_{A}$-formula represents a function in a theory $T \subseteq \Mod{A}$,
  then the formula also defines that function.
\end{proposition}

\begin{proof}   
  \emph{Proof.}
  Assume that $A(x_{1},\ldots,x_{n},y)$ represents a function $f$ in a theory $T$
  where $T \subseteq \Mod{A}$.
  We have to show that for all numbers $a_{1},\ldots,a_{n},b$,
  $A(\num{a_{1}},\ldots,\num{a_{n}},\num{b})$ is true in $\Mod{A}$ iff
  $f(a_{1},\ldots,a_{n}) = b$.
  For the `if' direction,
  assume that $f(a_{1},\ldots,a_{n}) = b$.
  By condition (i) in definition~\ref{def:repr-function},
  $\proves_{T} A(\num{a_{1}},\ldots,\num{a_{n}},\num{b})$.
  Since $T \subseteq \Mod{A}$,
  $A(\num{a_{1}},\ldots,\num{a_{n}},\num{b})$ is true in $\Mod{A}$.
  For the `only if' direction,
  assume that $A(\num{a_{1}},\ldots,\num{a_{n}},\num{b})$ is true in $\Mod{A}$.
  By condition (ii) for representability,
  $\proves_{T} \forall y(A(\num{a_{1}},\ldots,\num{a_{n}},y) \to y = \num{f(a_{1},\ldots,a_{n})})$.
  Since $T \subseteq \Mod{A}$,
  $A(\num{a_{1}},\ldots,\num{a_{n}},\num{b})$ is also true in $\Mod{A}$.
  Therefore,
  $\num{b} = \num{f(a_{1},\ldots,a_{n})}$ is true in $\Mod{A}$,
  and so $b = f(a_{1},\ldots,a_{n})$.
  \qed
\end{proof}

% \begin{proposition}{}{functional-ii}
%   If a formula $A(x_{1},\ldots,x_{n},y)$ satisfies condition (i) of the definition,
%   and it has the form $t = y$,
%   where $t$ is an $\L_{A}$-term,
%   then it also satisfies condition (ii) of the definition.
% \end{proposition}
% \begin{proof}
%   \emph{Proof.}
%   Assume that $A(x_{1},\ldots,x_{n},y)$ is $t = y$ and that it satisfies condition (i).
%   Let $a_{1},\ldots,a_{n}$ be numbers,
%   and let $b = f(a_{1},\ldots,a_{n})$.
%   By (i), $\proves_{T} t = \num{b}$.
%   By the first-order calculus,
%   it follows that $\proves_{T} \forall y(t = y \to y = \num{b})$.
%   \qed
% \end{proof}

% Exercise: prove the 1st-order calculus fact?

\begin{exercise}
  Suppose we swap `+' and `$\times$' everywhere in the Peano axioms.
  Does $x+y$ still represent addition in the resulting theory?
  Can you give an expression that does?
\end{exercise}

In the next two sections,
we'll show that
all recursive functions are representable in any
arithmetical theory that knows some basic facts about arithmetic.
Since the formula that \emph{represents} a function in such a theory
will also \emph{define} the function in $\L_{A}$,
it will follow that
all recursive functions are definable in $\L_{A}$.

As in the case of expressibility,
we can focus on functions
because the representability of recursive functions
entails the representability of recursive relations,
in any theory that can prove that $0 \not= 1$.

\begin{proposition}{}{char-func-repr}
  A relation $R$ is representable in a theory $T$ whenever
  its characteristic function $\chi_{R}$ is representable in $T$,
  provided that $\proves_{T} 0 \not= \num{1}$.
\end{proposition}
\begin{proof}
  \emph{Proof.}
  Assume $A(x_{1},\ldots,x_{n},y)$ represents the characteristic function $\chi_{R}$ of $R$ in $T$.
  This means that whenever $R$ holds of $a_{1},\ldots,a_{n}$,
  then $\proves_{T} A(\num{a_{1}},\ldots,\num{a_{n}},\num{1})$,
  by condition (i) for representability of functions.
  Moreover,
  whenever $R$ does not hold of $a_{1},\ldots,a_{n}$,
  then $\proves_{T} A(\num{a_{1}},\ldots,\num{a_{n}},0)$ by condition (i)
  and $\proves_{T} \forall yA(\num{a_{1}},\ldots,\num{a_{n}},y) \to y=0$ by condition (ii).
  Assuming that $\proves_{T} 0 \not= \num{1}$,
  it follows that $A(x_{1},\ldots,x_{n},1)$ represents $R$ in $T$.
  \qed
\end{proof}

\begin{exercise}
  Show that the converse is also true:
  if a relation is representable in a theory,
  then its characteristic function is representable in that theory.
\end{exercise}

  % Conversely,
  % assume that $A(x_{1},\ldots,x_{n})$ represents $R$ in $T$.
  % Let $B(x_{1},\ldots,x_{n},y)$ be the formula
  % \[
  %   (A(x_{1},\ldots,x_{n}) \land y\!=\!\num{1}) \lor
  %   (\neg A(x_{1},\ldots,x_{n}) \land y\!=\!0).
  % \]
  % I claim that $B(x_{1},\ldots,x_{n},y)$ represents the characteristic function $f_{R}$ of $R$ in $T$.
  % We have to verify the two conditions for representation.

  % We take the two possible values of $f_{R}(a_{1},\ldots,a_{n})$ in turn.
  % Assume first that $f_{R}(a_{1},\ldots,a_{n}) = 1$.
  % Then $R$ holds of $a_{1},\ldots,a_{n}$,
  % and by assumption $\proves_{T} A(\num{a_{1}},\ldots,\num{a_{n}})$.
  % In that case, we also have $\proves_{T} A(\num{a_{1}},\ldots,\num{a_{n}}) \land \num{1} = \num{1}$ and thereby $\proves_{T} B(\num{a_{1}},\ldots,\num{a_{n}},\num{1})$.
  % So the first condition for representability is satisfied.
  % The second condition requires that
  % $\proves_{T} \forall y(B(\num{a_{1}},\ldots,\num{a_{n}},y) \to y = \num{1})$.
  % This follows by construction of $B$.

  % By completely parallel reasoning,
  % we can show that
  % if $f_{R}(a_{1},\ldots,a_{n}) = 0$,
  % then $\proves_{T} B(\num{a_{1}},\ldots,\num{a_{n}},0)$ and
  % $\proves_{T} \forall y(B(\num{a_{1}},\ldots,\num{a_{n}},y) \to y = 0)$.

\section{Conditions for Representability I}

Here's the plan.
We'll show that every recursive function
can be defined by some $\L_A$-formula.
We'll then ask what an $\L_A$-theory needs to know in order for
that formula to represent the function.
Of course,
we can't go through the recursive functions one by one:
there are infinitely many.
Instead,
we'll proceed by induction on the construction of recursive functions
(as per definition~\ref{def:total-recursive} in Section~\ref{sec:minimization}).
We'll start with 
the base functions $z$ (zero), $s$ (successor), and $\pi^{n}_{i}$ (projection).
These are easily definable in $\L_A$,
and we'll see that
the formulas that define them also represent them,
in any theory whatsoever.
We'll then show that
if a function is constructed from other functions
by composition, primitive recursion, or regular minimization,
and these other functions are defined in $\L_A$ by certain formulas,
then we can construct an $\L_A$-formula out of these formulas that defines the new function.
We'll see that
this new formula represents the new function
in any theory that satisfies six conditions.

let's start with the zero function
that maps every number $a$ to $0$.
We need to find a formula $A(x,y)$
so that $A(\num{a},\num{b})$ is true (in $\Mod{A}$) iff $b = 0$.
Such a formula is not hard to find.

\begin{lemma}{}{zero-repr}
  The zero function $z$ is represented in every theory $T$ by the formula $x=x \land y=0$,
\end{lemma}

\begin{proof}
  \emph{Proof.}
  By definition~\ref{def:repr-function},
  $x=x \land y=0$ represents the zero function in a theory $T$ iff,
  all numbers $a$,
  \begin{cenumerate}
    \item[(i)] $\vdash_{T} \num{a}=\num{a} \land 0=0$, and
    \item[(ii)] $\vdash_{T} \forall y((\num{a}=\num{a} \land y=0) \to y = 0)$.
  \end{cenumerate}
  Both of these sentences are logical truths.
  So $x=x \land y=0$ represents the zero function in every theory $T$.
\end{proof}

Obviously,
$x=x \land y=0$ also \emph{defines} the zero function:
for any $a,b$,
$\num{a}=\num{a} \land \num{b}=0$ is true (in $\Mod{A}$) iff $b=0$.
As I mentioned above,
we don't need to check for definability separately:
as long as the theories $T$ in which a formula represents a function
include some true theory $T \subseteq \Mod{A}$,
the formula also defines the function (by Proposition~\ref{prop:repr-def}).

\begin{lemma}{}{succ-repr}
  The successor function $s$ is represented in every theory $T$ by the formula $s(x)=y$.
\end{lemma}

\begin{proof}
  \emph{Proof.}
  $s(x)=y$ represents the successor function in a theory $T$ iff,
  for all numbers $a$,
  \begin{cenumerate}
    \item[(i)] $\vdash_{T} s(\num{a}) = \num{s(a)}$, and
    \item[(ii)] $\vdash_{T} \forall y(s(\num{a})=y \to y = \num{s(a)})$.
  \end{cenumerate}
  Since $\num{s(a)}$ is $s(\num{a})$,
  both of these sentences are logical truths.
  So $s(x)=y$ represents the successor function in any theory $T$,
  including $Th(\Mod{A})$.
\end{proof}

% \begin{proof}
%   We need to show:
%   \begin{cenumerate}[(i)]
%     \item[(i)] For all $a$, $\vdash_{T} s(\num{a}) = \num{a+1}$.
%     \item[(ii)] For all numbers $a$, $\vdash_{T} \forall y(s(\num{a})=y \to y = \num{a+1})$.
%   \end{cenumerate}
%   (ii) follows from (i) by standard predicate logic.
%   (i) is a logical truth because the $\L_{A}$-numeral $\num{a+1}$ is $s(\num{a})$.
% \end{proof}

\begin{lemma}{}{proj-repr}
  Each projection function $\pi^{n}_{i}$ is represented in every theory $T$ by ${x_{1}=x_{1}} \land \ldots \land {x_{n}=x_{n}} \land {y=x_{i}}$.
\end{lemma}

\begin{proof}
  Exercise.
\end{proof}

\begin{exercise}
  Prove Lemma~\ref{lem:proj-repr}.
\end{exercise}

% \begin{proof}
%   We need to show:
%   \begin{cenumerate}[(i)]
%     \item For all $a_{1},\ldots,a_{n}$, $\vdash_{T} \num{a_{1}}=\num{a_{1}} \land \ldots \land \num{a_{n}}=\num{a_{n}} \land \num{a_{i}}=\num{a_{i}}$.
%     \item For all numbers $a_{1},\ldots,a_{n}$, $\vdash_{T} \forall y(\num{a_{1}}=\num{a_{1}} \land \ldots \land \num{a_{n}}=\num{a_{n}} \land y=\num{a_{i}} \to y = \num{a_{i}})$.
%   \end{cenumerate}
% \end{proof}

Now for the closure operations.
We start with composition.

Assume that
$h$ is the composition of two (one-place) functions $f$ and $g$,
so that $h(x) =f(g(x))$.
Assume that $f$ and $g$ are defined by formulas $F(x,y)$ and $G(x,y)$,
respectively.
We want to find a formula that defines $h$.
Note that $h(x) = y$ iff there is a $v$ such that $g(x) = v$ and $f(v) = y$.
So the following formula is a natural candidate:
\[
  \exists v(G(x,v) \land F(v,y)).
\]

\begin{lemma}{}{repr-closure-cn}
  If an $m$-place function $f$ is represented in a theory $T$ by a formula $F(x_{1},\ldots,x_{m},y)$,
  and $m$ $n$-place functions $g_{1},\ldots,g_{m}$ are represented in $T$ by formulas
  and $G_{1}(x_{1},\ldots,x_{n},y_{1}),\ldots,G_{m}(x_{1},\ldots,x_{n},y_{m})$,
  respectively,
  then the composition $h = Cn[f,g_{1},\ldots,g_{m}]$ is represented in $T$ by the formula
  \[
    \exists v_{1}\ldots \exists v_{m}\,(G_{1}(x_{1},\ldots,x_{n},v_{1}) \land \ldots \land
    G_{m}(x_{1},\ldots,x_{n},v_{m}) \land F(v_{1},\ldots,v_{m},y)).
  \]
\end{lemma}
\begin{proof}
  \emph{Proof.}
  I'll give the proof for the case where $n=1$ and $m=2$.
  The proof for arbitrary $n$ and $m$ is analogous.

  Condition (i) for representations requires that whenever $h(a) = b$ then
  \[
    \proves_{T} \exists v_{1}\exists v_{2}(G_{1}(\num{a},v_{1}) \land G_{2}(\num{a},v_{2}) \land F(v_{1},v_{2},\num{b})).
  \]
  So assume $h(a) = b$.
  Then there are $c_{1},c_{2}$ such that
  $g_{1}(a) = c_{1}$, $g_{2}(a) = c_{2}$, and $f(c_{1},c_{2}) = b$.
  Since $g_{1}$ and $g_{2}$ are represented by $G_{1}(x,y_{1})$ and $G_{2}(x,y_{2})$,
  respectively,
  and $f$ is represented by $F(x_{1},x_{2},y)$,
  we have
  \begin{gather*}
    \proves_{T} G_{1}(\num{a},\num{c_{1}}) \\
    \proves_{T} G_{2}(\num{a},\num{c_{2}}) \\
    \proves_{T} F(\num{c_{1}},\num{c_{2}},\num{b}).
  \end{gather*}
  The desired claim follows by the fact that $T$ is closed under first-order consequence.

  For condition (ii),
  we have to show that
  \[
    \proves_{T} \forall y(\exists v_{1}\exists v_{2}(G_{1}(\num{a},v_{1}) \land G_{2}(\num{a},v_{2}) \land F(v_{1},v_{2},y)) \to y = \num{f(a)}).
  \]
  This, too, follows from the representability conditions for $F$, $G_{1}$, and $G_{2}$,
  which yield
  \begin{gather*}
    \proves_{T} \forall y(G_{1}(\num{x},y) \to y = \num{c_{1}}) \\
    \proves_{T} \forall y(G_{2}(\num{x},y) \to y = \num{c_{2}}) \\
    \proves_{T} \forall y(F(c_{1},c_{2},y) \to y = \num{f(a)}).
  \end{gather*}
  \qed
\end{proof}

% \begin{proof}
%   For the first condition,
%   assume $h(a_{1},\ldots,a_{n}) = b$.
%   Then there are some $c_{1},\ldots,c_{m}$ such that
%   for all $g_{i}$,
%   $g_{i}(a_{1},\ldots,a_{n}) = c_{i}$ and $f(c_{1},\ldots,c_{m}) = b$.
%   Since each $g_{i}$ is represented by $G_{i}(x_{1},\ldots,x_{n},y_{i})$,
%   and $f$ by $F(x_{1},\ldots,x_{m},y)$,
%   we have
%   \begin{gather*}
%     \vdash_{Q} G_{1}(\num{a_{1}},\ldots,\num{a_{n}},\num{c_{1}}) \\
%     \vdash_{Q} \ldots \\
%     \vdash_{Q} G_{m}(\num{a_{1}},\ldots,\num{a_{n}},\num{c_{m}}) \\
%     \vdash_{Q} F(\num{c_{1}},\ldots,\num{c_{m}},\num{b}).
%   \end{gather*}
%   It follows (by closure under first-order consequences) that
%   \[
%     \vdash_{Q} \exists v_{1}\ldots \exists v_{m}\,(G_{1}(\num{a_{1}},\ldots,\num{a_{n}},v_{1}) \land \ldots \land
%     G_{m}(\num{a_{1}},\ldots,\num{a_{n}},v_{m}) \land F(v_{1},\ldots,v_{m},\num{b})).
%   \]
%   The first condition for representability is thereby satisfied.

%   The second is also satisfied,
%   for the assumption that $G_{1},\ldots,G_{m},F$ represent $g_{1},\ldots,g_{m},f$
%   means that
%   \begin{gather*}
%     \vdash_{Q} \forall y(G_{1}(\num{x},y) \to y = \num{c_{1}}) \\
%     \ldots\\
%     \vdash_{Q} \forall y(G_{m}(\num{x},y) \to y = \num{c_{m}}) \\
%     \vdash_{Q} \forall y(F(c_{1},\ldots,c_{m},y) \to y = \num{b}).
%   \end{gather*}
%   And this entails
%     \[
%         \vdash_{Q} \forall y(\exists v_{1}\ldots \exists v_{m}\,(G_{1}(\num{a},v_{1}) \land \ldots \land
%         G_{m}(\num{a},v_{m}) \land F(v_{1},\ldots,v_{m},y)) \to y = \num{b}).
%     \]
% \end{proof}

I leave the case of primitive recursion for last:
it is by far the hardest.
Let's turn to regular minimization.
Suppose $h = Mn[f]$, where $f$ is a regular function.
This means that
for any input number $x$,
$h$ returns the smallest number $y$ for which $f(x,y)$ is 0.
Assuming that $f$ is represented in $T$ by some formula $F(x,y)$,
we have $h(x) = y$ iff $F(x,y,0)$ and there is no $z < y$ such that $F(x,z,0)$.
We can directly translate this into $\L_{A}$:
\[
  F(x,y,0) \land \forall z(z < y \to \neg F(x,z,0)).
\]
This formula \emph{defines} $h$ in $\L_A$.
Some assumptions are needed for it to represent $h$ in a theory $T$.
Informally speaking,
the theory must have some idea of what $<$ means.
The following conditions are sufficient.

\begin{axioms}
  R1 & $\text{For all }a\text{, }\vdash_{T} \forall x (\num{a} < x \lor x = \num{a} \lor x < \num{a})\text{.}$\\
  R2 & $\vdash_{T} \neg \exists x (x < 0)\text{.}$\\
  R3 & $\text{For all }a > 0\text{, }\vdash_{T} \forall x (x < \num{a} \to (x = 0 \lor \ldots \lor x = \num{a-1}))\text{.}$\\
  R4$^{-}$ & $\text{for all }a > 0, \vdash_{T} \num{a} \ne 0$
\end{axioms}

Officially,
of course,
`<' isn't part of the language.
I assume here, and in what follows,
that `$t_{1} < t_{2}$' is short for `$\exists z(s(z) + t_{1} = t_{2})$',
where $z$ is a variable that doesn't occur in $t_{1}$ or $t_{2}$.

\begin{lemma}{}{repr-mn}
  If an $n$-place regular function $f$ is represented in a theory $T$ by a formula $F(x_{1},\ldots,x_{n},y)$,
  and $T$ satisfies the conditions R1, R2, R3, and R4$^{-}$,
  then the minimization $Mn[f]$ of $f$ is represented in $T$ by the formula
  \[
    F(x_{1},\ldots,x_{n},y,0) \land \forall z(z < y \to \neg F(x_{1},\ldots,x_{n},z,0)).
  \]
\end{lemma}

\begin{proof}
  \emph{Proof.}
  For readability, I assume that $n=1$.
  We have to show that the formula
  \[
    F(x,y,0) \land \forall z(z < y \to \neg F(x,z,0))
  \]
  satisfies the two conditions for representing the function $h = Mn[f]$ in $T$.
  That is,
  we have to show that whenever $h(a) = b$,
  then $T$ can prove:
  \begin{cenumerate}
    \item[(i)] $F(\num{a},\num{b},0) \land \forall z(z < \num{b} \to \neg F(\num{a},z,0))$.
    \item[(ii)] $\forall y(F(\num{a},y,0) \land \forall z(z < y \to \neg F(\num{a},z,0)) \to y = \num{b})$.
  \end{cenumerate}

  From the fact that $h = Mn[f]$ and $f(a) = b$, we know that
  $f(a,b) = 0$ and that $f(a,c) \neq 0$ for all $c < b$.
  Since $f$ is represented in $T$ by $F$,
  $T$ can prove
  \begin{equation}\tag{1}
    F(\num{a},\num{b},0)
  \end{equation}
  as well as
  \begin{equation}\tag{2}
    \forall y(F(\num{a},\num{c},y) \to y = \num{f(a,c)}),
  \end{equation}
  From (2) and R4$^{-}$,
  it follows that $T$ can prove $\neg F(\num{a},\num{c},0)$ for all $c < b$.
  By R3,
  $T$ can prove
  $\forall z(z < \num{b} \to (z = 0 \lor \ldots \lor z = \num{b-1}))$
  whenever $b > 0$.
  In that case,
  it follows that $T$ can prove
  \begin{equation}\tag{3}
    \forall z(z < \num{b} \to \neg F(\num{a},z,0)).
  \end{equation}
  For $b = 0$,
  (3) follows from R2.
  (i) is the conjunction of (1) and (3).

  For (ii).
  we show that $T$ can derive $y = \num{b}$ from
  \begin{equation}\tag{4}
    F(\num{a},y,0) \land \forall z(z < y \to \neg F(\num{a},z,0)).
  \end{equation}
  By (1), $T$ knows that $F(\num{a},\num{b},0)$.
  Together with (4), this implies $\neg (\num{b} < y)$.
  From (3) and (4), $T$ knows that $\neg (y < \num{b})$.
  By R1, $T$ can infer $y = \num{b}$.
  \qed
\end{proof}

Now for the hard part: primitive recursion.

\section{Conditions for Representability II}

Consider the factorial function that maps
each number $n$ to $n! = 1 \cdot 2 \cdot 3 \cdots n$.
The definition by primitive recursion is simple:
\begin{align*}
  0! & = 1 \\
  (n+1)! & = (n+1) \cdot n!
\end{align*}
We need to find a formula $F(x,y)$ that expresses this function in $\L_{A}$,
so that $F(x,y)$ is true of numbers $a$ and $b$ iff $b = a!$.

The trick is to see the recursive definition of $n!$ as defining a sequence:
$0!, 1!, 2!, \ldots, n!$.
The sequence has $n+1$ elements,
whose last element is $n!$.
Our formula $F(x,y)$ will say that \emph{$y$ is the $x+1$st element of the sequence $0!, 1!, \ldots n!$}.

Of course,
$\L_{A}$ doesn't have terms for sequences.
But we know that sequences of numbers can be coded as single numbers.
Suppose we can find a formula $\text{Entry}(x,i,y)$
that expresses ``$y$ is the $i$-th entry in the sequence coded by $x$''.
We can then define a formula $\text{Fact}_n(x)$
saying that
\begin{cenumerate}
  \item[(i)] the first entry in the sequence coded by $x$ is 1, and
  \item[(ii)] for all $i<n$, the $(i+1)$th entry in the sequence coded by $x$ is the product of the $i$th entry and $(i+1)$.
\end{cenumerate}
In other words,
$Fact_n(x)$ will say that $x$ codes the sequence $0!, 1!, \ldots, n!$.
We can then define $F(x,y)$ as
\[
  \exists z(\text{fact}_{x}(z) \land \text{Entry}(z,s(x),y)).
\]

The main task, then,
is to find the formula $\text{Entry}(x,i,y)$
that holds of numbers $x,i,y$ iff
$y$ is the $i$-th entry in the sequence coded by $x$.

In Section~\ref{sec:pr-examples},
we showed that there is a primitive recursive function $\mathrm{entry}(x,y)$ that
returns the exponent of the $y$-th prime in the prime factorization of $x$.
Now we're looking at an $\L_A$-formula $\text{Entry}(x,i,y)$ though,
and since the construction of $\mathrm{entry}$ used primitive recursion,
our previous work doesn't help us here.
In fact,
we won't code sequences of numbers in terms of prime exponents this time.

To explain the coding method we're going to use instead,
assume first that
we want to code a sequence $a_{1}, a_{2}, \ldots, a_{n}$ of numbers
all of which are below 9.
We could then simply
concatenate their decimal representation:
$1,7,0,7$ would be coded as $1707$.
To simplify accessing individual elements of the sequence,
we might store the indices of the elements in the code,
so that $1,7,0,7$ gets coded as $11273047$.
The third element can now be identified as the digit to the right of the '3'
(in decimal representation).
As it stands,
this doesn't quite work because the indices can also be among the coded elements,
as is the case for the number 1 in the example:
there are two digits to the right of a '1'.
We can disambiguate the indices by prefixing them with yet another digit, 9,
that doesn't occur among the coded numbers.
The code of $1,7,0,7$ becomes $911927930947$.
The $i$-th element can be retrieved as the unique digit to the right of '$9i$'
(in decimal representation).

We'll now adapt this scheme to code arbitrary sequences of numbers.
We obviously can't assume that all of the numbers are below 9.
We therefore code sequences not to base 10,
but to some base $p$ that it is at least 2 greater than
all numbers in the sequence and all index numbers
($p-1$ is used to mark the index numbers).
For convenience,
we'll always use a prime number as the base $p$.
The sequence $1, 12, 0$,
for example,
would therefore be coded in base 17 as
\[
  16 \pconcatseventeen 1 \pconcatseventeen 1 \pconcatseventeen 16 \pconcatseventeen 2 \pconcatseventeen 12 \pconcatseventeen 16 \pconcatseventeen 3 \pconcatseventeen 0,
\]
where `$\pconcatseventeen$' is the operation of concatenation in base 17.
If $q$ is the code number of a sequence in base $p$,
the $i$-th element of the sequence can be retrieved as
\begin{quote}
  alpha(p,q,i) = the unique number $x$, for which $(p-1) \pconcat i \pconcat x$ is part of the base-$p$ numeral of $q$.
\end{quote}
We'll see that this can be expressed in $\L_{A}$.

Our present coding scheme effectively codes sequences of numbers
as \emph{pairs} of numbers $\t{p,q}$:
$q$ is the actual code;
but to retrieve the elements,
one also needs to know the base $p$.
We can combine $p$ and $q$ in a single number by
using the pairing function that we met way back in Section~\ref{sec:cardinalities}:
\[
   \textrm{J}(x,y) = \frac{\mbox{\small 1}}{\mbox{\small 2}} (x+y)(x+y+1)+y
\]

Let $L$ and $R$ be functions that extract the elements of a pair encoded by $J$,
so that $L(J(x,y)) = x$ and $R(J(x,y)) = y$.
If we have coded a sequence of numbers $a_{1},\ldots,a_{n}$ by
$p$ and $q$ as described above,
and packaged these into a single number $c = \textrm{J}(p,q)$,
we can retrieve any element $a_{i}$ of the doubly coded sequence as
\[
  \text{beta}(c,i) = \text{alpha}(\textrm{L}(c),\textrm{R}(c),i).
\]
This is also expressible in $\L_{A}$.
That is,
there is a formula $\text{Beta}(x,i,y)$
that holds of $x,i,y$ iff $y$ is the $i$-th element of the sequence (doubly) coded by $x$.
This is formula $\text{Entry}(x,i,y)$ that we were looking for.

I'm not going to write down the $\L_{A}$-formula $\text{Beta}(x,i,z)$.
Instead,
I'll show that
$\text{beta}$ can be constructed by composition and regular minimization
from functions and relations that are obviously definable in $\L_{A}$
-- namely, from addition, multiplication, and identity.
These are defined,
respectively,
by $x+y = z$,
$x \times y = z$,
and $x=y$.
To ensure that
they are also \emph{represented} by these formulas in a theory $T$,
we need the following assumptions:

\begin{axioms}
  R4 & $\text{For all }a, b\text{, if }a \neq b\text{ then }\vdash_{T} \num{a} \neq \num{b}\text{.}$\\
  R5 & $\text{For all }a, b\text{, }\vdash_{T} \num{a} + \num{b} = \num{a+b}\text{.}$\\
  R6 & $\text{For all }a, b\text{, }\vdash_{T} \num{a} \cdot \num{b} = \num{a\cdot b}\text{.}$
\end{axioms}

Note that R4 subsumes R4$^{-}$.

\begin{lemma}{}{identity-repr}
   The identity relation is represented by $x=y$ in every theory $T$ that satisfies R4.
\end{lemma}
\begin{proof}
  \emph{Proof.}
  We need to show that for all $a,b$:
  \begin{cenumerate}
    \item[(i)] if $a = b$ then $\vdash_{T} \num{a} = \num{b}$.
    \item[(ii)] if $a \neq b$ then $\vdash_{T} \neg (\num{a} = \num{b})$.
  \end{cenumerate}
  (i) holds in any theory because $\num{a}$ and $\num{b}$ are the same term.
  (ii) holds by R4. \qed
\end{proof}

\begin{lemma}{}{plus-repr}
   The addition function is represented by $x+y=z$ in every theory $T$ that satisfies R5.
\end{lemma}
\begin{proof}
  \emph{Proof.}
  Condition (i) in the definition of representation is given by R5.
  Condition (ii) is a theorem of the predicate calculus.
  \qed
\end{proof}

\begin{lemma}{}{times-repr}
  The multiplication function is represented by $x\cdot y=z$ in every theory $T$ that satisfies R6.
\end{lemma}
\begin{proof}
  \emph{Proof.}
  Condition (i) in the definition of representation is given by R6.
  Condition (ii) is a theorem of the predicate calculus.
  \qed
\end{proof}

To show that $\text{beta}$ can be constructed by composition and regular minimization from these functions,
I'll use the following two lemmas.

\begin{lemma}{}{repr-closure-boolean}
  If some relations (with the same arity) are representable in a theory $T$
  then so are all truth-functional combinations of these relations.
\end{lemma}
\begin{proof}
  \emph{Proof.}
  Suppose $R_1$ and $R_2$ are $n$-ary relations and represented in $T$ by $A_1$ and $A_2$,
  respectively. 
  I show that $A_1 \land A_2$ represents the conjunction of $R_1$ and $R_2$,
  assuming $n=1$.
  We have to show that
  \begin{cenumerate}
    \item[(i)] if $R_{1}(a)$ and $R_{2}(a)$,
    then $\vdash_{T} A_{1}(\num{a}) \land A_{2}(\num{a})$;
    \item[(ii)] if it is not the case that $R_{1}(a)$ and $R_{2}(a)$,
    then $\vdash_{T} \neg (A_{1}(\num{a}) \land A_{2}(\num{a}))$.
  \end{cenumerate}

  For (i),
  assume $R_{1}(a)$ and $R_{2}(a)$.
  By the assumption that $A_{1}$ and $A_{2}$ represent $R_{1}$ and $R_{2}$,
  $T$ can prove $A_{1}(\num{a})$ and $A_{2}(\num{a})$.
  Then $T$ can also prove their conjunction.

  For (ii),
  assume it is not the case that $R_{1}(a)$ and $R_{2}(a)$.
  By the assumption that $A_{1}$ and $A_{2}$ represent $R_{1}$ and $R_{2}$,
  $T$ can prove $\neg A_{1}(\num{a})$ or $\neg A_{2}(\num{a})$.
  Either way, $T$ can prove their disjunction.

  The other cases are similarly trivial.
  \qed
\end{proof}

\begin{lemma}{}{repr-closure-bounded}
  If an $n+1$-ary relation $R(x_1,\ldots,x_n,y)$ is representable in a theory $T$,
  and $T$ satisfies R2, R3, and R5,
  then for all $k$,
  the $n$-ary relations $\forall y \!<\! k\, R(x_1,\ldots,x_n,y)$
  and $\exists y \!<\! k\, R(x_1,\ldots,x_n,y)$ are representable in $T$.
\end{lemma}
\begin{proof}
  \emph{Proof.}
  Assume that $R(x_{1},\ldots,x_{n},y)$ is represented in $T$ by $A(x_{1},\ldots,x_{n},y)$.
  For simplicity, I'll assume that $n=1$.
  I claim that $\forall y\!<\! k\, R(x,y)$ is represented in $T$ by
  $\forall y (y < \num{k} \to A(x,y))$,
  and $\exists y\!<\! k\, R(x,y)$
  by $\exists y (y < \num{k} \land A(x,y))$.
  
  For the universal quantifier,
  we have to show that $\forall y(y < \num{k} \to A(\num{a},y))$ satisfies the two representation conditions for relations:
  \begin{cenumerate}
    \item[(i)] if $\forall y < k R(a,y)$ then
      $\vdash_{T} \forall y (y < \num{k} \to A(\num{a},y))$,
    \item[(ii)] if $\neg \forall y < k R(a,y)$ then
      $\vdash_{T} \neg \forall y (y < \num{k} \to A(\num{a},y)$.
  \end{cenumerate}

  For (i), assume $\forall y < k R(a,y)$.
  We first consider the case where $k > 0$.
  Since $A$ represents $R$ in $T$,
  $T$ can prove $A(\num{a},\num{b})$ for all $b < k$.
  So $T$ can prove $\forall y(y\!=\!\num{b} \to A(\num{a},y))$ for all $b < k$.
  By R3,
  $T$ can prove $\forall y (y < \num{k} \to (y = 0 \lor \ldots \lor y = \num{k-1}))$.
  So $T$ can prove $\forall y (y < \num{k} \to A(\num{a},y))$.
  For $k = 0$,
  $T$ can prove $\neg \exists y (y < 0)$ by R2,
  which entails $\forall y (y < 0 \to A(\num{a},y))$.

  For (ii), assume $\neg \forall y < k R(a,y)$.
  Then there is some $b < k$ such that $\neg R(a,b)$.
  Since $A$ represents $R$,
  $T$ can prove $\neg A(\num{a},\num{b})$.
  Pick any $c$ with $k = b+(c+1)$.
  By R5,
  $T$ can prove $\num{b} + \num{c+1} = \num{k}$.
  Since $T$ can also prove $\num{c+1} = s(\num{c})$
  (because the two sides are the same term),
  $T$ can prove $\num{b} + s(\num{c}) = \num{k}$
  and thus also $\num{b} < \num{k}$,
  which is short for $\exists z(\num{b} + s(z) = \num{k})$.
  Hence $T$ can prove $\exists y (y < \num{k} \land \neg A(\num{a},y))$,
  which is equivalent to $\neg \forall y (y < \num{k} \to A(\num{a},y)$.

  The proof for $\exists y < k R(x_{1},\ldots,x_{n},y)$ is analogous.
\end{proof}

% It follows that x<y is representable as ∃z(∃v(z+s(v)=y) ∧ x+s(z)=y) in any
% theory that satisfies R1-R6.

The proof of the following lemma shows the construction of $\text{beta}$.

\begin{lemma}{Beta function Lemma}{beta}
  There is a function $\text{beta}$ such that
  for any finite sequence $a_{1}, \ldots, a_{n}$ of natural numbers,
  there is a number $c$ such that
  $\text{beta}(c,i) = a_{i}$ for all $1 \leq i \leq n$.
  Moreover,
  beta is representable in any theory $T$ that satisfies R1--R6.
\end{lemma}

\begin{proof}
  \emph{Proof.}

  I've explained above how $\text{beta}$ works.
  I'll now show how it can be constructed from addition, multiplication, and identity
  by composition and regular minimization.
  (If you pay close attention,
  you'll see that the construction also involves the projection functions,
  which we get for free by Proposition~\ref{prop:proj-repr}.)
  
  As explained above, beta is defined by composition from $\text{alpha}$, $L$ and $R$.
  \[
    \text{beta}(c,i) = \text{alpha}(\textrm{L}(c),\textrm{R}(c),i).
  \]
  $L$ and $R$ can be constructed by minimization and bounded quantification
  from $J$ and identity:
  \begin{eqnarray*}
    \textrm{L}(q) &=& \mu x\, \exists y\!\le\!q(\textrm{J}(x,y)=q) \\
    \textrm{R}(q) &=& \mu y\, \exists x\!\le\!q(\textrm{J}(x,y)=q)
  \end{eqnarray*}
  $J$ can be constructed by composition and regular minimization from addition, multiplication, and identity
  (and the constants 1 and 2,
  which can constructed from s and 0):
  \[
    \textrm{J}(x,y) = \mu z \, (2 \cdot z = (x+y) \cdot (x+y+1) + 2\cdot y).
  \]

  It remains to define $\text{alpha}$.
  Here is a more explicit version of the construction given above:
  \begin{eqnarray*}
    \text{alpha}(p,q,i) &=& \mu x\, ((p \dotminus 1) \pconcat i \pconcat x\,\,\mbox{is part$_{p}$ of}\,\, q).
  \end{eqnarray*}

  `$x \,\mbox{is part$_{p}$ of}\, y$' means
  `the base-$p$ numeral of $x$ is part of the base-$p$ numeral of $y$',
  and '$\dotminus$' is truncated subtraction,
  which we can construct as follows:
  \begin{eqnarray*}
    x \dotminus y &=& \mu z\, ((y\!<\!x \,\to\, y\!+\!z\!=\!x) \,\land\, (\neg(y\!<\!x) \,\to\, z\!=\!0)) \\
    x < y &\Leftrightarrow& \exists z\!\le\!y (x + s(z) = y).
  \end{eqnarray*}

  The part$_{p}$ relation can be constructed in terms of base-$p$ concatenation:

  \begin{eqnarray*}
    x \,\mbox{is part$_{p}$ of}\, y &\Leftrightarrow& \exists v\!\le\!y \, \exists w\!\le\!y \, (v \pconcat x \pconcat w = y \,\lor\, v \pconcat x = y \, \\
                                    && \lor\, x \pconcat v = y \, \lor \, x \!=\! y)
  \end{eqnarray*}

  To construct base-$p$ concatenation,
  we use the function $\eta(p,x)$
  that returns the smallest power of $p$  greater than $x$.
  That is,
  $\eta(p,x)$ is the next-greater number after $x$ whose base-$p$ numeral
  is longer than the base-$p$ numeral of $x$.

  \begin{eqnarray*}
    x \pconcat y &=& x \cdot \eta(p,y) +y \\
    \eta(p,x) &=& \mu y\,((y\,\,\mbox{is power of prime}\,\, p \\
                 && \,\land\, \, y\!>\!x \,\land\, y\!>\!1) \, \lor \,  (\neg(p\,\,\mbox{is prime}) \,\land\, y\!=\!0))
  \end{eqnarray*}

  Finally, we construct `$x$ is power of $p$' and `$x$ is prime':

  \begin{eqnarray*}
    x\,\,\mbox{is power of prime}\,\,p &\Leftrightarrow& x\!\not=\!0 \,\land\,
   p\,\,\mbox{is prime} \\
   && \land\, \forall y\!\le\!x\, (y\,\,\mbox{divides}\,\,x
   \,\to\, y\!=\!1 \,\lor\, p\,\,\mbox{divides}\,\,y) \\
  x\,\,\mbox{is prime} &\Leftrightarrow& x \ne 0 \text{ and } x \ne 1 \text{ and } \forall
    y\!<\!x\,(y\,\,\mbox{divides}\,\,x \,\to\, y\!=\!1 \,\lor\, y\!=\!x) \\
  x\,\,\mbox{divides}\,\,y &\Leftrightarrow& \exists z\!\le\!y\,(y=x\cdot z)
  \end{eqnarray*}

  To be clear,
  this chain of definitions doesn't directly show how to
  express the relevant functions and relations in $\L_{A}$.
  The expressions on the right-hand side aren't $\L_{A}$-formulas;
  they are metalinguistic descriptions of certain functions and relations.
  The chain shows
  how the $\mathrm{beta}$ function can be constructed from
  simpler functions and relations by
  composition, regular minimization, truth-functional combination, and bounded quantification.
  A few simple functions and relations remain undefined:
  addition, multiplication, identity, projection, and the constants 0, 1, 2.
  [I guess we should reduce 1, 2 to 0 and addition?]
  By Lemmas~\ref{lem:identity-repr}, \ref{lem:plus-repr}, \ref{lem:times-repr},
  these are representable in any theory $T$ that satisfies R1--R6.
  By Lemmas~\ref{lem:repr-closure-cn}, \ref{lem:repr-closure-mn}, \ref{lem:repr-closure-boolean}, and \ref{lem:repr-closure-bounded},
  composition, regular minimization, truth-functional combination, and bounded quantification preserve representability
  in any theory $T$ that satisfies R1--R6.
  It follows that $\mathrm{beta}$ is representable in any such theory.
  \qed
\end{proof}

With this, we can finally show that representability is closed under primitive recursion.
Assume that $h = Pr[f,g]$,
With the help of the beta function lemma,
we could construct a formula $S(c,x,k)$
for ``$c$ codes the sequence $h(x,0), h(x,1), \ldots, h(x,k)$''.
We could then define $H(x,y,z)$ as $\exists c(S(c,x,y) \land \text{Beta}(c,y,z))$,
and show that $H$ represents $h$ in $T$.
But we can take a shortcut:

\begin{lemma}{}{repr-closure-pr}
  If $h$ is defined from an $f$ and $g$ by primitive recursion,
  and $f$ and $g$ are representable in a theory $T$ that satisfies R1--R6,
  then $h$ is also representable in $T$.
\end{lemma}
\begin{proof}
  \emph{Proof.}
  Assume that $h = Pr[f,g]$,
  meaning that
  \begin{align*}
    h(x_{1},\ldots,x_{n},0) & = f(x_{1},\ldots,x_{n}) \\
    h(x_{1},\ldots,x_{n},n+1) & = g(x_{1},\ldots,x_{n},n,h(x_{1},\ldots,x_{n},n)).
  \end{align*}
  For readability, I assume that $n=1$.

  Let $\text{Seq}$ be the relation
  that holds between numbers $c,x,k$
  iff $c$ codes the sequence $h(x,0), \ldots, h(x,k)$.
  This can be defined from $f$, $g$, and $\text{beta}$
  by boolean combination and bounded quantification:
  \[
    \text{Seq}(c,x,k) = \text{beta}(c,1) = f(x) \text{ and } \forall i \leq k(\text{beta}(c,i+1) = g(x,i,\text{beta}(c,i))).
  \]
  By the assumption that $f$ and $g$ are representable in $T$
  and lemmas \ref{lem:beta}, \ref{lem:repr-closure-bounded} and \ref{lem:repr-closure-boolean},
  $\text{Seq}$ is representable in $T$.
  By lemma \ref{lem:repr-closure-mn},
  so is the function
  \[
    d(x,k) = \mu c \, \text{Seq}(c,x,k)
  \]
  that returns the code of $h(x,0), \ldots, h(x,k)$.
  From this,
  we can define $h$ by composition, projection, and successorhood:
  \[
    h(x,k) = \text{beta}(d(x,k),s(k)).
  \]
  By lemmas \ref{lem:succ-repr}, \ref{lem:repr-closure-cn} and \ref{lem:proj-repr},
  $h$ is representable in $T$.
  \qed
\end{proof}

\iffalse

These are obviously expressible in $\L_{A}$.
To ensure that they are also representable in a theory $T$,
we have to assume that $T$ satisfies the following conditions:

\begin{axioms}
  R4 & $\text{For all }a, b\text{, if }a \neq b\text{ then }\vdash_{T} \num{a} \neq \num{b}\text{.}$\\
  R5 & $\text{For all }a, b\text{, }\vdash_{T} \num{a} + \num{b} = \num{a+b}\text{.}$\\
  R6 & $\text{For all }a, b\text{, }\vdash_{T} \num{a} \cdot \num{b} = \num{a\cdot b}\text{.}$
\end{axioms}

\begin{lemma}{}{identity-repr}
   The identity relation is represented by $x=y$ in every theory $T$ that satisfies R4.
\end{lemma}
\begin{proof}
  \emph{Proof.}
  We need to show that for all $a,b$:
  \begin{cenumerate}
    \item[(i)] if $a = b$ then $\vdash_{T} \num{a} = \num{b}$.
    \item[(ii)] if $a \neq b$ then $\vdash_{T} \neg (\num{a} = \num{b})$.
  \end{cenumerate}
  (i) holds in any theory because $\num{a}$ and $\num{b}$ are the same term.
  (ii) holds by R4. \qed
\end{proof}

\begin{lemma}{}{plus-repr}
   The addition function is represented by $x+y=z$ in every theory $T$ that satisfies R5.
\end{lemma}
\begin{proof}
  \emph{Proof.}
  Condition (i) in the definition of representation is given by R5.
  Condition (ii) is a theorem of the predicate calculus.
  \qed
\end{proof}

\begin{lemma}{}{times-repr}
  The multiplication function is represented by $x\cdot y=z$ in every theory $T$ that satisfies R6.
\end{lemma}
\begin{proof}
  \emph{Proof.}
  Condition (i) in the definition of representation is given by R6.
  Condition (ii) is a theorem of the predicate calculus.
  \qed
\end{proof}

\begin{lemma}{}{repr-closure-bounded}
  Assume that $T$ satisfies R2, R3, and R5,
  and an $n+1$-ary relation $R$ is represented in $T$ by a formula $A(x_{1},\ldots,x_{n},y)$.
  Then for all $k$,
  the $n$-ary relation $\forall y < k R(x_{1},\ldots,x_{n},y)$
  is represented in $T$ by $\forall y (y < \num{k} \to A(x_{1},\ldots,x_{n},y))$,
  and $\exists y < k R(x_{1},\ldots,x_{n},y)$
  by $\exists y (y < \num{k} \land A(x_{1},\ldots,x_{n},y))$.
\end{lemma}
\begin{proof}
  \emph{Proof.}
  As usual, I'll focus on the case of $n=1$ for readability.
  For the universal quantifier,
  we have to show that $\forall y(y < \num{k} \to A(\num{a},y))$ satisfies the two representation conditions for relations:
  \begin{cenumerate}
    \item[(i)] if $\forall y < k R(a,y)$ then
      $\vdash_{T} \forall y (y < \num{k} \to A(\num{a},y))$,
    \item[(ii)] if $\neg \forall y < k R(a,y)$ then
      $\vdash_{T} \neg \forall y (y < \num{k} \to A(\num{a},y)$.
  \end{cenumerate}

  For (i), assume $\forall y < k R(a,y)$.
  We first consider the case where $k > 0$.
  Since $A$ represents $R$ in $T$,
  $T$ can prove $A(\num{a},\num{b})$ for all $b < k$.
  So $T$ can prove $\forall y(y\!=\!\num{b} \to A(\num{a},y))$ for all $b < k$.
  By R3,
  $T$ can prove $\forall y (y < \num{k} \to (y = 0 \lor \ldots \lor y = \num{k-1}))$.
  So $T$ can prove $\forall y (y < \num{k} \to A(\num{a},y))$.
  For $k = 0$,
  $T$ can prove $\neg \exists y (y < 0)$ by R2,
  which entails $\forall y (y < 0 \to A(\num{a},y))$.

  For (ii), assume $\neg \forall y < k R(a,y)$.
  Then there is some $b < k$ such that $\neg R(a,b)$.
  Since $A$ represents $R$,
  $T$ can prove $\neg A(\num{a},\num{b})$.
  Pick any $c$ with $k = b+(c+1)$.
  By R5,
  $T$ can prove $\num{b} + \num{c+1} = \num{k}$.
  Since $T$ can also prove $\num{c+1} = s(\num{c})$
  (because the two sides are the same term),
  $T$ can prove $\num{b} + s(\num{c}) = \num{k}$
  and thus also $\num{b} < \num{k}$,
  which is short for $\exists z(\num{b} + s(z) = \num{k})$.
  Hence $T$ can prove $\exists y (y < \num{k} \land \neg A(\num{a},y))$,
  which is equivalent to $\neg \forall y (y < \num{k} \to A(\num{a},y)$.

  The proof for $\exists y < k R(x_{1},\ldots,x_{n},y)$ is analogous.
\end{proof}

% It follows that x<y is representable as ∃z(∃v(z+s(v)=y) ∧ x+s(z)=y) in any
% theory that satisfies R1-R6.

\begin{lemma}{}{repr-closure-boolean}
  If two $n$-ary relations $R_{1}$ and $R_{2}$ are represented in a theory $T$
  by formulas $A_{1}$ and $A_{2}$, respectively,
  then $A_{1} \land A_{2}$ represents the conjunction of $R_{1}$ and $R_{2}$ in $T$
  $A_{1} \lor A_{2}$ represents the disjunction of $R_{1}$ and $R_{2}$ in $T$
  and $\neg A_{1}$ represents the negation of $R_{1}$ in $T$.
\end{lemma}
\begin{proof}
  Let's look at the case for conjunction, assuming $n=1$.
  We have to show that
  \begin{cenumerate}
    \item[(i)] if $R_{1}(a)$ and $R_{2}(a)$,
    then $\vdash_{T} A_{1}(\num{a}) \land A_{2}(\num{a})$;
    \item[(ii)] if it is not the case that $R_{1}(a)$ and $R_{2}(a)$,
    then $\vdash_{T} \neg (A_{1}(\num{a}) \land A_{2}(\num{a}))$.
  \end{cenumerate}

  For (i),
  assume $R_{1}(a)$ and $R_{2}(a)$.
  By the assumption that $A_{1}$ and $A_{2}$ represent $R_{1}$ and $R_{2}$,
  $T$ can prove $A_{1}(\num{a})$ and $A_{2}(\num{a})$.
  Then $T$ can also prove their conjunction.

  For (ii),
  assume it is not the case that $R_{1}(a)$ and $R_{2}(a)$.
  By the assumption that $A_{1}$ and $A_{2}$ represent $R_{1}$ and $R_{2}$,
  $T$ can prove $\neg A_{1}(\num{a})$ or $\neg A_{2}(\num{a})$.
  Either way, $T$ can prove their disjunction.

  The other cases are similarly trivial.
  \qed
\end{proof}

Together,
these lemmas show that beta is representable in any theory $T$
that satisfies R2--R6,
where R4 subsumes R4$^{-}$.

\begin{lemma}{Beta-function Lemma}{beta}
  There is a function $\text{beta}$ such that
  for any finite sequence $a_{1}, \ldots, a_{n}$ of natural numbers,
  there is a number $c$ such that
  $\text{beta}(c,i) = a_{i}$ for all $1 \leq i \leq n$.
  Moreover,
  beta is representable in any theory $T$ that satisfies R1--R6.
\end{lemma}
\begin{proof}
  \emph{Proof.}
  I've explained above how this function $\text{beta}$ can be defined
  by composition, minimization, bounded quantification, and boolean combination
  from addition, multiplication, identity, and the successor function.
  By lemmas \ref{lem:s-repr}, \ref{lem:identity-repr}, \ref{lem:plus-repr}, \ref{lem:times-repr},
  this basis is representable in any theory $T$ that satisfies R1--R6.
  By lemma \ref{lem:repr-closure-composition}, \ref{lem:repr-closure-minimization},
  \ref{lem:repr-closure-bounded}, and \ref{lem:repr-closure-boolean},
  representability in any such $T$ is closed under
  composition, minimization, bounded quantification, and boolean combination.
  \qed
\end{proof}

With this, we can prove our final lemma.

\begin{lemma}{}{repr-closure-pr}
  If $h$ is defined from an $f$ and $g$ by primitive recursion,
  and $f$ and $g$ are representable in a theory $T$ that satisfies R1--R6,
  then $h$ is also representable in $T$.
\end{lemma}
\begin{proof}
  \emph{Proof.}
  Assume that $h = Pr[f,g]$,
  meaning that
  \begin{align*}
    h(x_{1},\ldots,x_{n},0) & = f(x_{1},\ldots,x_{n}) \\
    h(x_{1},\ldots,x_{n},n+1) & = g(x_{1},\ldots,x_{n},n,h(x_{1},\ldots,x_{n},n)).
  \end{align*}
  For readability, I assume that $n=1$.

  With the help of the beta function lemma,
  it's not hard to construct a formula $S(c,x,k)$
  for ``$c$ codes the sequence $h(x,0), h(x,1), \ldots, h(x,k)$''.
  We could then define $H(x,y,z)$ as $\exists c(S(c,x,y) \land \text{Beta}(c,y,z))$,
  and show that $H$ represents $h$ in $T$.

  But let's take a shortcut.
  Let $\text{Seq}$ be the \emph{relation}
  that holds between numbers $c,x,k$
  iff $c$ codes the sequence $h(x,0), \ldots, h(x,k)$.
  This can be defined from $f$, $g$, and $\text{beta}$
  by boolean combination and bounded quantification:
  \[
    \text{Seq}(c,x,k) = \text{beta}(c,1) = f(x) \text{ and } \forall i \leq k(\text{beta}(c,i+1) = g(x,i,\text{beta}(c,i))).
  \]
  By the assumption that $f$ and $g$ are representable in $T$
  and lemmas \ref{lem:beta}, \ref{lem:repr-closure-bounded} and \ref{lem:repr-closure-boolean},
  $\text{Seq}$ is representable in $T$.
  By lemma \ref{lem:repr-closure-mn},
  so is the function
  \[
    d(x,k) = \mu c \, \text{Seq}(c,x,k)
  \]
  that returns the code of $h(x,0), \ldots, h(x,k)$.
  From this,
  we can define $h$ by composition, projection, and successorhood:
  \[
    h(x,k) = \text{beta}(d(x,k),s(k)).
  \]
  By lemmas \ref{lem:closure-s}, \ref{lem:repr-closure-composition} and \ref{lem:repr-closure-projection},
  $h$ is representable in $T$.
  \qed
\end{proof}

\fi

\section{Putting the pieces together}

\begin{theorem}{}{recrep}
  All total recursive functions are representable in any theory that satisfies R1--R6.
\end{theorem}
\begin{proof}
  By induction on the definition of total recursive functions,
  using lemmas \ref{lem:s-repr}, \ref{lem:zero-repr}, \ref{lem:plus-repr}, \ref{lem:times-repr},
  \ref{lem:repr-closure-composition}, \ref{lem:repr-closure-minimization}, and \ref{lem:repr-closure-pr}.
\end{proof}

\begin{corollary}{}{recrelrep}
  All recursive relations are representable in any theory that satisfies R1--R6.
\end{corollary}
\begin{proof}
  By the theorem,
  the lemma on characteristic functions,
  and the fact that any theory $T$ that satisfies R6 can prove $0 \neq 1$.
\end{proof}





Let's reflect on what we've achieved.
We've shown that all recursive functions are representable in any theory
that knows a few facts about the natural numbers,
summarized in R1--R6.

\begin{axioms}
  R1 & $\vdash_T \neg \exists x (x < 0)$\\
  R2 & $\text{For all }a > 0\text{, }\vdash_{T} \forall x (x < \num{a} \to (x = 0 \lor \ldots \lor x = \num{a-1}))\text{.}$\\
  R3 & $\text{For all }a\text{, }\vdash_{T} \forall x (\num{a} < x \lor x = \num{a} \lor x < \num{a})\text{.}$\\
  R4 & $\text{For all }a, b\text{, }\vdash_{T} \num{a} + \num{b} = \num{a+b}\text{.}$\\
  R5 & $\text{For all }a, b\text{, }\vdash_{T} \num{a} \cdot \num{b} = \num{a\cdot b}\text{.}$\\
  R6 & $\text{For all }a, b\text{, if }a \neq b\text{ then }\vdash_{T} \num{a} \neq \num{b}\text{.}$
\end{axioms}

Each of R1-R6 specifies one or more sentences that must be contained in T.
As such,
R1-R6 can be seen as an axiomatization of a theory.
This minimal theory is not especially elegant,
especially if we were to unpack the '<' relation in R1-R3.
An elegant alternative that satisfies R1-R6 is the theory Q,
also known as Robinson arithmetic.

\begin{theorem}{}{Q-rep}
  All recursive functions and relations are representable in Q.
\end{theorem}
\begin{proof}
  \emph{Proof.}
  We need to show that Q satisfies R1--R6.

  \emph{R1.}
  We show that $Q$ contains $\neg \exists x (x < 0)$.
  Fix any $x,z$.
  By Q3, either $x = 0$ or $\exists y\, x = s(y)$.
  If $x=0$,
  $s(z) + x = s(z) + 0 = s(z)$ by Q4, hence $s(z) + x \neq 0$ by Q2.
  If, alternatively, $\exists y\, x = s(y)$,
  then $s(z) + x = s(z) + s(y) = s(s(z) + y)$ by Q5,
  hence $s(z) + x \neq 0$ by Q2.
  So Q2--Q5 entail that $\forall x \neg \exists z(s(z) + x = 0)$.
  
  \smallskip%
  \emph{R2.} % Lemma 14.11 in BJ.
  We show by induction on $a$ that whenever $a > 0$ then
  $\vdash_Q \forall x (x < \num{a} \to (x = 0 \lor \ldots \lor x = \num{a-1}))$.
  \emph{Base:} $a=1$.
  We show that $\vdash_Q \forall x (x < \num{1} \to x = 0)$.
  Assume $x < \num{1}$;
  i.e.\ $\exists z (s(z) + x = s(0))$.
  Suppose for reductio that $x\!\not= 0$.
  By Q3, $\exists y\, x\!=\!s(y)$;
  so $s(z)+s(y) = s(0)$;
  so $s(s(z)+y) = s(0)$ by Q5, 
  and $s(z)+y = 0$ by Q1;
  if $y=0$ then $s(z)+0=s(z)=0$ contradicting Q2;
  if $y=s(w)$ then $s(z)+s(w)=s(s(z)+w)=0$, again contradicting Q2.
  \emph{Induction step:}
  Assume $x < s(\num{a})$,
  i.e.\ $\exists z(s(z) + x = s(\num{a}))$.
  By Q3,
  either $x=0$ or $\exists y\, x=s(y)$.
  In the second case,
  $s(z) + s(y) = s(\num{a})$,
  so $s(s(z) + y) = s(\num{a})$ by Q5,
  and $s(z) + y = \num{a}$ by Q1;
  so $y < \num{a}$.
  By induction hypothesis,
  $y = 0 \lor \ldots \lor y = \num{a-1}$,
  so $x= s(y)$ is one of $1, \ldots, \num{a}$.
  Combining both cases, we have $x=0 \lor \ldots \lor x = \num{a}$.

  \smallskip%
  \emph{R3.} % Lemme 14.13 in BJ
  % R3 & $\text{For all }a\text{, }\vdash_{T} \forall x (\num{a} < x \lor x = \num{a} \lor x < \num{a})\text{.}$
  We show by induction on $a$ that $\vdash_Q \forall x (\num{a} < x \lor x = \num{a} \lor x < \num{a})$.
  \emph{Base:} $a=0$.
  By Q3,
  for all $x$ either $x=0$ or $\exists y\, x=s(y)$.
  In the second case,
  $\exists y (s(y) + 0 = x)$ by Q4,
  and so $0<x$ by definition.
  So $\forall x(x = 0 \lor 0 < x)$.
  \emph{Induction step:}
  Let $x$ be any number.
  We show that $s(\num{a}) < x \lor x = s(\num{a}) \lor x < s(\num{a})$.
  By Q3,
  either $x=0$ or $\exists y\, x=s(y)$.
  If $x=0$ then $x < s(\num{a})$ because
  $s(\num{a}) + 0 = s(\num{a})$ by Q4 and hence $\exists z(s(z) + 0 = s(z))$.
  Assume $\exists y\, x=s(y)$.
  By induction hypothesis,
  $\num{a} < y \lor y = \num{a} \lor y < \num{a}$.
  If $\num{a} < y$ then
  $\exists z(s(z) + \num{a} = y)$ and
  $s(z) + s(\num{a}) = s(y)$ by Q5;
  so $s(\num{a}) < x$.
  If $y = \num{a}$ then $x = s(\num{a})$.
  If $y < \num{a}$ then
  $\exists z(s(z) + y = \num{a})$ and
  $s(z) + s(y) = s(\num{a})$ by Q5;
  so $x < s(\num{a})$.

  \smallskip%
  \emph{R4.}
  % R4 & $\text{For all }a, b\text{, }\vdash_{T} \num{a} + \num{b} = \num{a+b}\text{.}$\\
  We show by induction on $b$ that
  for all $a,b$,
  $\vdash_Q \num{a} + \num{b} = \num{a+b}$.
  \emph{Base}: $b=0$.
  Then $\num{a} + \num{b} = \num{a+b}$ by Q4.
  \emph{Induction step:} $b=s(c)$.
  By induction hypothesis,
  $\num{a} + \num{c} = \num{a+c}$.
  By Q5,
  $\num{a} + s(\num{c}) = s(\num{a} + \num{c}) = s(\num{a+c}) = \num{a + s(c)} = \num{a+b}$.

  \smallskip%
  \emph{R5.}
  We show by induction on $b$ that
  for all $a,b$,
  $\vdash_Q \num{a} \cdot \num{b} = \num{a\cdot b}$.
  \emph{Base}: $b=0$.
  Then $\num{a} \cdot \num{b} = \num{a\cdot b}$ by Q6.
  \emph{Induction step:} $b=s(c)$.
  Then
  $\num{a} \cdot s(\num{c}) = \num{a} \cdot \num{c} + \num{a}$ by Q7,
  $= \num{a\cdot c} + \num{a}$ by induction hypothesis,
  $= \num{a\cdot c + a}$ by R4,
  $= \num{a \cdot b}$.

  \smallskip%
  \emph{R6.} % Lemma 14.7 in BJ.
  We need to show that if $a \ne b$,
  then $\vdash_Q \num{a} \ne \num{b}$.
  Assume $a < b$.
  We show by induction on $a$ that $\vdash_Q \num{a} \ne \num{b}$.
  \emph{Base:} $a=0$.
  Then $\num{b} = \num{s(b-1)})$
  and hence $0 \ne \num{b}$ by Q2.
  \emph{Induction step:} $a=s(c)$.
  Then $b = s(d)$ for some $d$ with $c < d$.
  By induction hypothesis,
  $\vdash_Q \num{c} \ne \num{d}$.
  So $\vdash_Q s(\num{c}) \ne s(\num{d})$ by Q1.
  The case for $b < a$ is analogous.
  \qed

\end{proof}

\begin{theorem}{}{PA-rep}
  All recursive functions and relations are representable in PA.
\end{theorem}
\begin{proof}
  \emph{Proof}.
  Immediate from Theorem~\ref{thm:Q-rep} and the fact (
  Proposition~\ref{prop:PAentailsQ}) that
  PA extends Q.
  \qed
\end{proof}

We also have a converse:

\begin{theorem}{}{repr-rec}
  If a relation is representable in an axiomatizable and consistent $\L_{A}$-theory,
  then it is recursive.
\end{theorem}
\begin{proof}
  \emph{Proof.}
  Assume $A(x_{1},\ldots,x_{n})$ represents $R$ in an axiomatizable and consistent $\L_{A}$-theory $T$.
  This means that if $R$ holds of some numbers $a_{1},\ldots,a_{n}$,
  then $T$ can prove $A(\num{a_{1}},\ldots,\num{a_{n}})$,
  and if $R$ does not hold of $a_{1},\ldots,a_{n}$,
  then $T$ can prove $\neg A(\num{a_{1}},\ldots,\num{a_{n}})$.
  Now one can computably enumerate all (codes of) theorems of $T$.
  To check whether $R$ holds of some numbers $a_{1},\ldots,a_{n}$,
  we can wait until either $A(\num{a_{1}},\ldots,\num{a_{n}})$ or $\neg A(\num{a_{1}},\ldots,\num{a_{n}})$ appears on this list.
  By a lazy appeal to the Church-Turing thesis,
  it follows that $R$ is recursive.
  \qed
\end{proof}


At the beginning of section xx,
I asked about definability.
I announced that all recursive functions and relations are definable in the language of arithmetic $\L_{A}$.
Can you see why this holds?

\begin{theorem}{}{definability}
  All recursive functions and relations are definable in $\L_{A}$.
\end{theorem}
\begin{proof}
  \emph{Proof.}
  All axioms of Q are true in the standard model of arithmetic.
  It follows that the formulas that represent recursive functions in Q
  also define those functions.
  \qed
\end{proof}

We know that r.e. relations result from recursive relations by existential quantification.
Now remember that an $n$-ary relation $R$ is r.e. iff
there is an $n-1$-ary recursive relation $Q$ such that
$R(a_{1},\ldots,a_{n})$ iff $\exists y Q(a_{1},\ldots,a_{n},y)$.
It follows that $\L_{A}$ can express all r.e. relations.
But we also know that not all r.e. relations are recursive.
It follows that $\L_{A}$ can express more than just the recursive relations.

It follows that the complete truth of $\L_{A}$ is not computably axiomatizable!
This is an abstract version of Gödel's Incompleteness Theorem.


\iffalse


We've just seen that
the converse does not hold.
Some relations that are definable in $\L_{A}$ are not recursive.
That's because the recursive relations aren't closed under existential quantification.
They also aren't closed under universal quantification.

Maybe move hierarchy to next chapter:
PA can prove all true $\Delta_{0}$ sentences. etc.


One can define a whole hierarchy of relations
expressible in $\L_{A}$,
in terms of the quantifiers used in their definitions.
At the bottom of the hierarchy are the relations expressible by
formulas without any unbounded quantifiers
(except for the quantifier that occurs in the definition of $<$;
for this purpose,
it is cleaner to add '$<$' as a primitive relation to $\L_{A}$).
These are called $\Delta_{0}$-formulas,
and the relations $\Delta_{0}$-relations.
At the next level are two classes of relations:
the $\Sigma_{1}$-relations are defined by
($\Sigma_{1}$-)formulas that prefix existential quantifiers to $\Delta_{0}$-formulas,
the $\Pi_{1}$-relations are defined by
($\Pi_{1}$-)formulas that prefix universal quantifiers to $\Delta_{0}$-formulas.
Prefixing universal quantifiers to a $\Sigma_{1}$-formula yields a $\Pi_{2}$-formula;
prefixing existential quantifiers to a $\Pi_{1}$-formula yields a $\Sigma_{2}$-formula.
These define the $\Sigma_{2}$-relations and the $\Pi_{2}$-relations, respectively.
And so on.
The recursive relations,
it turns out,
are all $\Sigma_{1}$:
they can be expressed by formulas that prefix existential quantifiers to $\L_{A}$-formulas
without unbounded quantifiers.

[It's useful to think of
this hierarchy not so much in terms of language,
but in terms of relations.
We start with the computable relations $\Delta_{0}$,
then consider relations defined by existential or universal quantification from them,
and so on.]


In fact,
we know more about what a representation of recursive relations in $\L_{A}$ looks like.
Note that every term of $\L_{A}$ expresses a polynomial:
it is (arithmetically) equivalent to an expression of the form
$a_{0} + a_{1} \cdot x + a_{2} \cdot x^{2} + \ldots + a_{n} \cdot x^{n}$.
Since the only predicate in $\L_{A}$ is equality,
all atomic $\L_{A}$-formulas express equations between polynomials.
It follows that any relation that is expressible in $\L_{A}$ can
be defined from an equation between polynomials by logical operations.
Now,
one can show that all recursive relations (and therefore also all r.e. relations)
are definable in $\L_{A}$ by formulas that prefix existential quantifiers to an equation between polynomials.
This is the result of the so-called MRDP Theorem,
named after Matiyasevich, Robinson, Davis, and Putnam.
The proof is much too difficult to be included here.

\begin{exercise}
  Say that a relation $R$ is \emph{weakly represented} by an $\L_{A}$-formula $A(x_{1},\ldots,x_{n})$ in a theory $T$ iff for all numbers $a_{1},\ldots,a_{n}$,
  \[
    R(a_{1},\ldots,a_{n}) \text{ iff } \vdash_{T} A(\num{a_{1}},\ldots,\num{a_{n}}).
  \]
  Explain the following facts:
  \begin{enumerate}[(a)]
    \item A relation can be weakly represented in $T$ without being strongly represented in $T$.
    \item If $R$ is weakly represented in an axiomatizable and consistent theory, then it is r.e.
    \item All recursive relations are weakly represented in any $\L_{A}$-theory that is   consistent with Q.
    (Hint:
    We know that each recursive relation $R$ is represented in Q by some formula $A$.
    Let $\hat{Q}$ be the conjunction of the seven axioms of Q,
    and consider the formula $\hat{Q} \to A$.)
  \end{enumerate}
\end{exercise}

\fi

\iffalse

\section{A look ahead}

We're going to prove Gödel's incompleteness theorem.
We'll show that
every consistent theory of arithmetic (in the language $\L_{A}$)
with a computable set of axioms
is \emph{incomplete} in the sense that
there are arithmetical sentences $A$ which
the theory can neither prove nor refute.

We focus on arithmetic for two reasons.
One, it's a comparatively simple and familiar branch of maths.
If arithmetic can't be adequately axiomatized,
then evidently the same is true for more powerful theories.
Two, the proof of Gödel's theorem requires that
the theory in question has the resources to
express basic facts about what can and can't be proved.
Arithmetic theories satisfy this requirement.

(In a sense, arithmetic is the computational fragment of maths: computations on
any domain can be encoded as arithmetic computations.
Once we've shown that every total recursive function is expressible in $L_{A}$, what
remains to be shown is that if we code the elements of other domains as numbers,
computable operations on these domains will be recursive operations on numbers.)

Of course,
some theories of arithmetic are complete.
The restriction to a computable set of axioms is important.

\begin{definition}{Recursive Axiomatizability}{recursive-axiomatizability}
  A theory is \emph{recursively axiomatizable} if it contains all and only the
  sentences derivable from some recursive set of axioms.
\end{definition}

Remember that proofs from computable axioms are ``verifiable''.
There is an algorithm for checking that something is a proof.
We've already seen that
algorithms can generally be represented as operating on numbers,
with a suitable coding and decoding of the inputs and outputs.
We can code each $\L_{A}$-sentence and each sequence of $\L_{A}$-sentences by a number,
called the gn.
Since there is an algorithm
for checking whether a sequence is a proof of some target sentence,
it follows by Church's Thesis that
the relation Prf(x,y) is recursive.

Prf is a relation between numbers.
As such,
we may wonder if it can be expressed in $\L_{A}$,
in terms of $+$, $\times$, $s$, and $0$.
The answer is yes.
So there is an $\L_{A}$-formula $Prf(x,y)$ so that
$Prf(n,m)$ is true (in the standard model of arithmetic) iff
$n$ codes a proof of the sentence coded by $m$.
From this,
we can construct a formula $Prov(y)$ as $\exists x Prf(x,y)$ so that
$Prov(y)$ is true iff
$y$ is provable.
Again,
this will be a purely arithmetical formula,
couched in terms of $+$, $\times$, $s$, and $0$.

Using an ingenious trick due to Gödel,
we'll then show that
for every $\L_{A}$-formula
there is an $\L_{A}$-sentence that is true iff
the formula is true of the gödel number of that very sentence.
Thus,
in particular,
there is a sentence $G$ that is true iff
$\neg Prov(x)$ is true of $G$.
That is,
we'll find an arithmetical sentence $G$ that is true iff it is not provable.

Now suppose $G$ is provable,
in some computably axiomatized theory $T$.
Then $G$ is false,
as it is true iff it is not provable.
So if an arithmetical theory $T$ doesn't prove false sentences,
then it can't prove $G$.
In this case,
$G$ is true.
So $T$ can't prove its negation either,
as the negation is false.
So any sound (computably axiomatized) $\L_{A}$-theory is incomplete.

This result is sometimes called the \emph{semantic incompleteness theorem}.
It is ``semantic'' because it involves the concept of arithmetical truth,
which is a semantic concept.
Gödel himself focussed on a different version of the incompleteness theorem
that only relies on syntactic concepts of arithmetical theories.
He showed that
any axiomatic $\L_{A}$-theory of reasonable strength can prove
all true statements of the form $Prf(n,m)$ and $\neg Prf(n,m)$.
xxxx

What we need to show, then, is that
the Prf relation can be expressed in $\L_{A}$
and, moreover, that reasonably strong arithmetical theories can
prove all true statements of the form $Prf(n,m)$ and $\neg Prf(n,m)$.

In this chapter, we are going to show something much more general:
every recursive relation $R$ is expressible in $\L_{A}$.
and reasonably strong arithmetical theories can prove all true statements of the form $R(n,m)$ and $\neg R(n,m)$.
This more general fact will help get a deeper understanding of
the nature and limitations of axiomatized theories.

\begin{exercise}
  Show that if a theory is r. ax. and complete then it is decidable. (appeal
  lazily to Church's Theorem)
\end{exercise}


\fi

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "logic3.tex"
%%% End:
